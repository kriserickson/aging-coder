{
  "questions": [
    {
      "name": "What are Kris's key technical skills?",
      "context": "Kris is a full-stack, production-first engineer and technical leader with 25+ years delivering and operating customer-facing systems across web, mobile, and large retail device fleets. His differentiator is breadth with real depth: he can design architecture, implement the hard parts end-to-end, and keep systems reliable and evolvable over years—especially under real constraints (retail hardware, multi-channel flows, legacy migrations, and revenue-critical uptime).\n\n**Languages (real production experience):** TypeScript, JavaScript, PHP, C#, Python, Java, Kotlin, Swift, VB, and C, with earlier production work in Perl and Ruby.\n\n**Frontend engineering (web UI at scale):** Kris is highly fluent in TypeScript/JavaScript and comfortable shipping complex SPAs and PWAs in Vue and React (also Angular). He handles the unglamorous but critical parts of frontends—state complexity, performance tuning, incremental migration, build tooling, and keeping UI codebases maintainable as they grow.\n\n**Runtimes & frameworks (pragmatic backend delivery):** Kris has built substantial backends and service layers across multiple ecosystems and can move between them based on the problem and team context:\n- **Node.js / TypeScript:** Express, Hapi, Hono, Next.js, Nuxt\n- **.NET / C#:** .NET Core, ASP.NET Core\n- **PHP:** Laravel, Symfony, Slim\n- **Python:** FastAPI\n\nHe’s comfortable designing and implementing REST and GraphQL APIs, integrating third-party partners, and building service boundaries that support multi-channel systems (web ↔ kiosk ↔ mobile) where correctness, reliability, and operability matter.\n\n**Distributed systems & operational engineering:** Kris has designed and supported systems with real-world distributed constraints—retries, idempotency, safe rollouts, telemetry, and failure handling. He’s comfortable with event-driven and messaging patterns (especially with solace) and with building the operational tooling required to keep systems stable in production.\n\n**Mobile & device platforms:** Kris has built and shipped on Android and iOS, including native work in Kotlin/Java and Swift, plus cross-platform development (Flutter, Cordova). He’s comfortable with service-style components and bridging to compiled/native libraries when needed—an important skill set when products extend beyond browsers into kiosks and other field-deployed devices.\n\n**Databases, caching, and data plumbing:** Kris works confidently across relational and NoSQL stores including MySQL, PostgreSQL, SQLite, MongoDB, Redis, and CouchDB. He understands the tradeoffs between transactional correctness, throughput, caching, and operational simplicity—particularly in systems where reporting, payments, and partner trust depend on reliable numbers.\n\n**DevOps, CI/CD, and operability:** Kris is hands-on with Docker and Kubernetes and has built/maintained CI/CD pipelines in GitHub Actions, GitLab CI, and Jenkins. He approaches DevOps as ‘make it operable’: repeatable deployments, safe releases, and strong observability so teams can diagnose issues quickly and avoid costly downtime.\n\n**Observability & production diagnostics:** Kris has worked with and shipped systems instrumented using Kibana, OpenSearch, OpenTelemetry, Sentry, New Relic, and Splunk. He uses observability to drive outcomes—debugging production issues, identifying customer friction/abandonment points, and improving system reliability—rather than treating monitoring as a box-check.\n\n**AI/ML & applied computer vision:** Kris has 10+ years of applied ML/CV experience in production photo workflows, primarily using OpenCV across Windows kiosk, Linux/.NET Core imaging services, and Android service implementations. He’s also hands-on with modern AI stacks (PyTorch, Hugging Face Transformers, Scikit-learn) and LLM workflow patterns, with a pragmatic bias toward approaches that actually outperform in production (e.g., leveraging strong low-cost foundation models when fine-tuning data/ROI isn’t there).\n\n**Cloud exposure (transparent scope):** Kris has worked within systems deployed on AWS/GCP/Azure and understands the operational concepts, but he’s transparent that he has not built greenfield infrastructure from scratch in those clouds and still has depth to build there. He learns quickly and is comfortable operating within existing cloud environments.\n\n**Modernization under constraints:** Kris has repeatedly modernized long-lived revenue systems—migrating stacks (including Windows-only components to Linux/.NET Core), introducing proven technologies at the right time, and keeping legacy and modern systems interoperable without breaking the business."
    },
    {
      "name": "Tell me about Kris's management experience",
      "context": "At Storefront—a small company that ultimately ran with a tight, high-impact development group—Kris led delivery by coordinating closely with the development team and project managers while partnering directly with key business stakeholders to decide what to build next and why, consistently prioritizing the work that delivered the most value. In his Director of Software Development role, he owned the practical “glue” work: aligning goals, translating business outcomes into clear technical plans, unblocking execution, and keeping the roadmap grounded in real constraints and customer impact. He also invested heavily in team growth, mentoring senior engineers while coaching newer developers across a wide range of backgrounds—from boot-camp grads with strong prior careers to PhD-level hires who were brilliant technically but new to shipping software in a business context—so the team could move faster without sacrificing quality or reliability."
    },
    {
      "name": "What major projects has Kris led?",
      "context": "Kris has led multiple long-running, revenue-critical product lines at Storefront, taking them from early concept through years (and decades) of real-world production operation across major retail partners. The work spans a white-label e-commerce platform, high-volume in-store kiosk systems, distributed remote management at massive device scale, and customer-facing file transfer and payment flows that materially changed adoption, revenue, and loss prevention.\n\n1) Storefront White-Label E-Commerce Platform (1999/2000–present)\n\nThe Storefront platform began in 1999 as a consulting engagement, but in early 2000 Kris helped drive the evolution into a configurable, white-label e-commerce product. A pivotal early milestone came when a platform customer asked Storefront to create an online photo ordering system for the Windows XP era. In 2001, online photo ordering was a rapidly expanding market with comparatively few established competitors, and that customer request became the catalyst for Storefront’s strategic shift toward photo commerce.\n\nKris led the transformation from “generic commerce” into “photo commerce”: building systems that supported photo-specific workflows (uploading, previewing, editing, product configuration), expanded product catalogs (prints evolving into photo products and print-on-demand), and the operational realities of photo fulfillment and retail integration. Critically, this wasn’t a one-off storefront—it became a repeatable platform used by 10+ major retailers and partners, including Rite Aid, Fred Meyer, King Soopers, Smith’s, Duane Reade, Benavides, Fuji Mexico, and CVS Mexico.\n\nThe platform also enabled cross-channel behavior that mattered commercially: a significant share of revenue came from mixed journeys—customers ordering online and printing/picking up via kiosk, or starting in-store and completing on the web. That kind of “web ↔ kiosk” continuity is hard to get right because it requires consistent product rules, order state, pricing/promotions, identity/session bridging, and predictable fulfillment handoffs. Kris led the engineering decisions and sequencing that kept the system evolvable while still stable enough to run for decades.\n\n2) Windows Photo Kiosk Platform (millions of prints, $1B+ sales influence)\n\nBuilding on the photo-commerce shift, Kris helped lead the creation of Storefront’s Windows Photo Kiosk product line—the in-store consumer experience that processed millions of prints and contributed to over $1B in sales across the business (with revenue split roughly 50/50 between kiosk and web, plus a large volume of orders that started on the web and were printed at the kiosk).\n\nThese kiosks weren’t “a screen on a PC.” They were full retail systems that had to be resilient, easy for non-technical store staff to support, and operationally predictable across thousands of locations. Kris led the product and technical direction that made the kiosk a real platform: the customer UI and ordering flow, the integration points to printing/lab systems and inventory constraints, and the end-to-end transaction path that retail partners could operationalize.\n\nStorefront also iterated on the kiosk concept into adjacent products as consumer behavior shifted—like a ringtone kiosk and a music kiosk (including CD burning and iPod upload workflows). That wasn’t novelty; it demonstrated Kris’s ability to reuse core platform capabilities (catalog, pricing, UI patterns, fulfillment/entitlements, operational telemetry) while adapting the product to the constraints and customer expectations of different eras.\n\n3) Remote Management & Monitoring Platform (30,000+ devices, 12,000+ requests/min)\n\nKris led the development and expansion of a remote management platform that started as “kiosk monitoring” and evolved into a distributed control plane for an entire fleet of retail devices and connected services. At scale, this platform supported 30,000+ devices and backend throughput on the order of 12,000 requests per minute, while also being robust enough to support multi-country deployments and varied retail environments.\n\nThe impact was both operational and financial:\n\nEliminated massive field-visit costs: Early in the Rite Aid rollout, the company responsible for in-store installs reportedly made 2x what Storefront made selling kiosk software—because every update and fix required expensive hands-on service visits. Kris’s remote update capability changed that equation: software could be rolled out and patched without spending six figures on in-store visits every time something needed to change.\n\nReduced downtime with actionable telemetry: The platform didn’t just say “a kiosk is down.” It enabled Storefront to detect and act on real retail failure modes—kiosks out of paper, stuck states, device health issues—so Storefront could notify store staff to fix problems quickly and restore sales.\n\nImproved funnel performance via real usage signals: Kris used the telemetry to identify where customers abandoned the flow (which pages or steps drove drop-off), enabling targeted UX and reliability improvements that directly impacted completion rate and revenue.\n\nMade sales/accounting trustworthy in messy retail realities: In some deployments, kiosk orders were paid at the counter. The remote system enabled accurate sales figures so shrinkage (loss/theft/mismatches) could be identified and addressed—critical for retail partner trust and for maintaining the program at scale.\n\nOver time, the remote management foundation expanded beyond Windows kiosks to cover lab/print systems, experiments like digital advertising, and later device generations including Android kiosks—showing that Kris didn’t build a one-generation tool, but a durable operational platform that could adapt as hardware and retail strategies changed.\n\n4) Kiosk File Transfer + Payment System (Node.js/React) — adoption + shrinkage wins\n\nKris led the creation of a modern file transfer system designed to remove a major point of friction: customers previously had to plug phones into kiosks or bring flash drives/memory cards. The new flow let customers scan a barcode and upload photos to the kiosk without physical connection—cleaner, faster, and far more aligned with how people actually carried photos as smartphones took over.\n\nThe outcome was immediate and measurable: kiosk usage increased ~50% once customers no longer had to plug their phones in.\n\nThe project then expanded from “transfer” into “payments” using the same core infrastructure: session identification + secure handoff. Kris recognized that if you can securely connect a user’s phone session to a kiosk session, you can also use that to handle payment in a way that reduces both friction and risk. That meant:\n\nreducing the need for customers to type credit card details on a public kiosk, and\n\navoiding expensive payment hardware devices in the kiosk itself.\n\nWhen payment was introduced through this infrastructure, sales increased and shrinkage disappeared—a rare combination that retail partners love because it improves both top-line revenue and loss prevention at the same time.\n\n5) Distributed SaaS platform for customizable products (shared services across channels)\n\nAlongside the core kiosk + web business, Kris also led/owned substantial parts of a distributed SaaS platform that supported customizable products and shared capabilities across channels (web, kiosk, mobile). The through-line here is not just “built services,” but building operable services—systems designed to be monitored, debugged, rolled out safely, and incrementally modernized while keeping revenue systems running.\n\nLeadership and team impact (how he led these efforts)\n\nAcross these projects, Kris led engineering in a way that matched Storefront’s reality: a small company where priorities must be chosen carefully and every developer needs leverage. At peak, he coordinated a team of ~15 developers, averaged around 10, and delivered major outcomes even in the final year with a team of ~6. He coordinated between engineering and project managers, worked directly with key business partners to prioritize the roadmap for maximum stakeholder value, and kept delivery grounded in what would move revenue, reliability, and partner trust.\n\nHe also built strong teams by mentoring across a wide range of backgrounds—supporting senior developers while helping newer engineers ramp quickly, from boot-camp graduates with prior careers to PhD hires who were technically strong but new to business software delivery. That mentorship mattered because Storefront’s products weren’t toy apps—they were mission-critical systems running in retail, where reliability, operational clarity, and trust with partners determine whether the program grows or gets shut down."
    },
    {
      "name": "There is really only one job listed here, has Kris worked anywhere else?",
      "context": "Before Storefront, Kris held two professional software roles that helped shape his “modernize without breaking production” approach. At TRIUMF (May–Dec 1997) he contributed to updating internal business systems, working with legacy Oracle Forms–based workflows and helping move pieces of that functionality toward intranet/web-style tooling. The work required understanding existing operational processes, preserving correctness, and making incremental changes that improved usability without disrupting day-to-day operations.\n\nAt Canfor (Mar–Dec 1998) he built a Visual Basic application that replaced binder-based handling of Material Safety Data Sheets (MSDS) with a searchable digital system accessible across terminals. That project was practical, compliance-adjacent software: ingesting and organizing messy source information, making it easy to find the right document quickly, and ensuring staff could reliably access current safety data when they needed it.\n\nHe also has multiple consulting engagements over the years (kept intentionally generic on the resume primarily for non-disclosure/confidentiality reasons, and secondarily to keep the resume focused). Much of that work was in mobile delivery: Kris shipped 10+ greenfield mobile apps spanning iOS, Android, Windows Phone, and BlackBerry—from straightforward consumer utilities (e.g., store locator and account-style apps) to more complex, operational systems such as apps that helped companies track delivery drivers in real time, including map-driven UI, live updates, and reliability considerations when devices are in the field.\n\nGoing further back, Kris gained early leadership and business ownership experience outside tech: from roughly 1986–1996 (when not in school), he worked for Elephant Painting and later took over the business when the previous owners moved on. That period built durable instincts around delivery commitments, customer communication, scheduling/estimation, and taking ownership of outcomes—skills that carried forward into how he runs software projects and teams."
    },
    {
      "name": "How has Kris worked with AI/ML technologies?",
      "context": "Kris has applied AI/ML in real production photo systems for more than a decade—well before the current LLM boom—primarily through computer vision for consumer photo workflows. At Storefront, he built and evolved imaging capabilities used across the Windows Photo Kiosk and online photo ordering platform, including automated photo enhancements (color correction pipelines), classic consumer-photo fixes (red-eye reduction), and practical image analysis features built largely on OpenCV.\n\nThat work spanned multiple platform generations:\n- Windows kiosk era: OpenCV-based imaging ran directly on Windows kiosks, and the Storefront Imaging API was initially Windows-only.\n- Modernization era (2019+): the imaging stack was moved to Linux and .NET Core (early .NET Core 1.1 timeframe), preserving core photo workflows while modernizing deployment and operations.\n- Android kiosk era: imaging capabilities were also delivered on Android as a Java service that leveraged cross-compiled OpenCV C components—adapting the same CV foundation to mobile/embedded constraints.\n\nKris’s computer-vision work focused on features that made large consumer photo libraries usable and improved downstream product generation quality. A key example was similar-image stacking: Kris implemented near-duplicate grouping so users saw clean stacks instead of long runs of essentially identical photos. The implementation combined perceptual hashing (pHash), color-histogram similarity, and capture date/time signals to robustly cluster real-world images despite minor edits, lighting shifts, or burst-mode sequences. He also implemented face detection and intelligent auto-cropping for templated products—especially auto-photobook generation—with support for multiple faces, safe margins, and aspect-ratio constraints so crops looked intentional rather than random. Kris additionally explored early OpenCV-style classification signals (e.g., coarse scene/object indicators like grass/animals) as groundwork for richer organization/search experiences, though Storefront never shipped a full search product on top of those labels.\n\nIn his final year at Storefront, Kris expanded into modern generative AI and LLM-driven product work with a pragmatic, production-minded approach:\n- Image-processing automation: he prototyped Python-based pipelines initially using PyTorch, later switching portions to Pillow when deterministic image processing was the better fit than model-driven approaches.\n- Image generation integrations: he integrated multiple image-generation APIs (including DALL·E, Stability.ai, and Flux) to explore a key customer promise—helping users produce a sellable product image without requiring Photoshop-level skills. In practice, this also enabled demo-ready experiences without requiring customers to supply source imagery; analytics showed negligible direct sales impact, but it validated UX flows and reduced demo friction.\n- LLM product-description generation: he built an early-stage system to generate improved product descriptions for Storefront’s customizable-products SaaS platform. It combined existing product descriptions with user-supplied creation metadata (title and other inputs) and LLM-derived classification of the user’s created image to produce more complete, consistent copy.\n\nTo operate these AI features responsibly and cost-effectively—especially the more expensive image generation—Kris implemented an ‘AI proxy’ layer that enforced practical safeguards. The proxy focused on abuse prevention, cost control, and safe operation (e.g., gating and filtering requests, limiting expensive calls, and ensuring the system could be monitored and throttled), rather than relying on a fully developed brand-voice or editorial workflow, since the description generator was still early-stage.\n\nKris has also experimented with model adaptation and fine-tuning techniques (e.g., LoRA and related lightweight approaches) using PyTorch and Hugging Face Transformers. However, he deliberately did not ship fine-tuned models to production: the available domain data was insufficient to outperform strong, low-cost foundation models, and in evaluations—particularly around the product-description generator—small/cheap hosted foundation models consistently outperformed locally-run or fine-tuned attempts.\n\nSeparately, Kris has used AI-assisted coding tools since 2021 (e.g., GitHub Copilot and newer agentic/IDE workflows like Cursor/Windsurf-style environments) as a force multiplier for prototyping and refactoring, while maintaining senior-engineering rigor around correctness, maintainability, and operational ownership."
    },
    {
      "name": "Can you expand on Kris's enterprise SaaS experience?",
      "context": "Kris has 25+ years building, operating, and modernizing enterprise SaaS platforms where “enterprise” means real partner integrations, strict reliability expectations, and systems that must evolve without breaking revenue. At Storefront, he helped turn an early consulting engagement (1999) into a configurable white-label platform used by major retailers and partners, including Rite Aid, Fred Meyer, King Soopers, Duane Reade, Smith’s, Benavides, Fuji Mexico, and CVS Mexico. The platform supported high-volume photo commerce across both web and in-store kiosks, with customer journeys that often crossed channels (order online, print/pick up in-store), requiring consistent catalog rules, pricing/promotions, identity/session handling, order state, and fulfillment handoffs.\n\nKris’s enterprise SaaS experience is grounded in scale and operability across a broad international footprint. The Storefront ecosystem ran in Canada, the U.S., Mexico, Sweden, Germany, Norway, the U.K., France, Denmark, the Netherlands, and Belgium—each with its own retail constraints and operational realities. He also led a remote management and monitoring platform that started as kiosk monitoring and grew into a distributed control plane for a large device fleet (30,000+ devices; ~12,000 requests/minute). That platform reduced downtime and operating cost by enabling remote updates and configuration changes that would otherwise require expensive in-store service visits, provided actionable telemetry (device down, out-of-paper, health signals), and surfaced funnel behavior to identify where customers abandoned the flow so teams could fix the highest-impact friction points.\n\nOn the commercial side, Kris built enterprise capabilities that improved partner trust and profitability. He implemented reporting and transaction visibility that made sales figures reliable even in environments where kiosk orders were sometimes paid at the counter—enabling shrinkage to be detected and addressed. He also led work on a kiosk file-transfer and payment system that removed customer friction (no need to plug phones into kiosks), driving ~50% higher kiosk usage; when payment was handled through that secure session infrastructure, sales increased and shrinkage disappeared.\n\nMore recently, Kris co-architected and delivered a distributed SaaS platform focused on selling photo finishing products through Shopify (with an eye toward expanding to other commerce platforms over time). This included building the integration surface area required for enterprise e-commerce—product catalog sync, pricing rules, order ingestion and lifecycle, fulfillment/lab integration, and partner operational support—while also integrating Storefront’s photo editing/customization experience directly into third-party e-commerce sites so customers could personalize photo products on the partner’s platform without being bounced through a separate system. Across all of these efforts, Kris consistently balances modernization with continuity: incremental upgrades, safe releases, and operational tooling that keeps long-lived revenue systems stable while still moving forward."
    },
    {
      "name": "What measurable outcomes came from those projects?",
      "context": "Measurable outcomes from Kris’s major projects show up in longevity, scale, revenue impact, adoption lift, and hard operational savings:\n\n25+ years of continuous production operation (platform durability): Kris helped architect and modernize a white-label e-commerce + photo commerce platform that has remained operational for over 25 years, supporting 10+ major retail partners and multiple product generations without a “stop-the-world rewrite.” The measurable outcome here is longevity under real load, plus sustained partner usage across shifting consumer and retail environments.\n\nHigh-volume photo commerce with enterprise retail reach: Across web + kiosk channels, the platform processed millions of prints per year and supported a meaningful share of large retail photo finishing programs. In particular, Rite Aid’s photo finishing peaked around ~$1B/year in sales, and Storefront’s ecosystem captured value across both web ordering and in-store kiosk printing/pickup flows—meaning revenue wasn’t isolated to one channel but enabled the combined journey.\n\nRemote Management Platform at fleet scale: Kris led the evolution of remote management from simple kiosk monitoring into a distributed control plane supporting 30,000+ devices with sustained throughput around 12,000 requests/minute. The measurable outcomes weren’t just scale, but operational leverage: remote updates/configuration reduced dependence on expensive in-store servicing and enabled proactive issue response (down devices, out-of-paper, etc.), keeping revenue systems available and reducing downtime.\n\nField-service cost avoidance (real dollars saved): Early on, the kiosk install/servicing vendor in Rite Aid reportedly earned ~2× what Storefront earned from kiosk software—because ongoing updates and fixes required in-store visits. Kris’s remote update/management capability directly reduced that burden. He’s described avoiding six-figure service costs that would otherwise recur when updates required physical visits (the concrete outcome: updates and maintenance shifted from truck-roll economics to software economics).\n\nFile transfer modernization drove adoption: Moving customers from “plug your phone into the kiosk / bring a USB stick” to barcode-based file transfer increased kiosk usage by ~50%. That’s a clear, measurable funnel improvement attributable to reducing friction at the exact point where customers used to stall.\n\nPayments modernization improved revenue integrity: Using the same secure session infrastructure to handle payment reduced friction and eliminated key retail loss modes: after payment was instituted through this flow, sales increased and shrinkage disappeared (especially in counter-payment environments). That’s a rare “up + down” metric pair: higher sales plus lower loss.\n\nHardware cost avoidance at kiosk scale: By shifting payment away from requiring specialized kiosk payment hardware, the solution avoided credit-card hardware costs across thousands of kiosks, while also improving the customer experience (less card entry on public kiosks) and lowering operational complexity."
    },
    {
      "name": "How has Kris used AI/ML and modern tools to improve delivery?",
      "context": "Kris has used AI/ML and modern developer tooling as leverage to improve delivery: faster iteration without lowering the bar on correctness, maintainability, or operability. Since 2021 he’s championed AI-assisted coding (GitHub Copilot plus modern agentic/IDE workflows like Cursor and Windsurf-style environments) to accelerate routine implementation, refactoring, test scaffolding, and the repetitive “glue” work that usually slows teams down—while keeping changes small, reviewable, and production-safe. He treats these tools as amplifiers rather than autopilot: generated code still gets the same senior-engineering scrutiny (edge cases, error handling, readability, architectural fit, and operational considerations). He also applies AI beyond coding assistance with hands-on experience in PyTorch and Hugging Face Transformers, prompt engineering, and practical evaluation of fine-tuning approaches like LoRA-style adaptation experiments (including SIT-style experimentation), but stays pragmatic—preferring strong low-cost foundation models when data, ROI, latency, or operational complexity don’t justify fine-tuning. Related writing on his blog includes: Leveraging LLMs for Coding: Insights and Real-World Experiences https://agingcoder.com/posts/leveraging-llms-for-coding-insights-and-real-world-experiences/\n ; The Trough of Disillusionment https://agingcoder.com/posts/the-trough-of-disillusionment/\n ; LLMs and Coding 6 months later https://agingcoder.com/posts/llms-and-coding-6-months-later/\n ; Book Review: Vibe Coding https://agingcoder.com/posts/book-review-vibe-coding/ On the product and platform side, Kris also has hands-on AI/ML experience that goes beyond coding assistance. He has worked with PyTorch and Hugging Face Transformers, and he has experimented with model adaptation and fine-tuning techniques such as LoRA and related lightweight approaches (including SIT-style experimentation), alongside prompt engineering and structured-output techniques. In practice, he evaluates these techniques the way a product-minded engineer should: by measuring whether they outperform strong foundation models given available domain data, latency, cost, and operational complexity. For example, in experiments around LLM-driven content generation workflows, he found that small, inexpensive hosted foundation models often beat local or fine-tuned approaches when the training data wasn’t sufficient—so he optimized for outcomes and maintainability rather than insisting on fine-tuning for its own sake.\n\nFinally, Kris has applied “modern tools” broadly—not just AI—to improve delivery: adopting better observability and diagnostics (OpenTelemetry-style instrumentation and error tracking), tightening CI/CD loops, and using automation to make systems easier to ship and operate. The consistent theme is leverage: use the newest tools where they create real advantage, keep the bar for correctness high, and build workflows that make teams faster without sacrificing reliability."
    },
    {
      "name": "Can you describe Kris's approach to modernizing legacy systems?",
      "context": "Kris approaches legacy modernization as an engineering discipline: preserve what works, reduce risk with tests and observability, and evolve systems incrementally so the business keeps running. Two long-standing influences on his approach are Martin Fowler’s “Refactoring” and Michael Feathers’ “Working Effectively with Legacy Code,” especially the idea that you can’t modernize confidently without a safety net. Kris is deliberate about building that safety net—adding regression coverage (often starting with characterization tests), tightening feedback loops via CI, and instrumenting systems so changes can be validated in production without guesswork. The goal is to create the feeling of security required to make meaningful upgrades without breaking everything.\n\nA good example is the original Windows kiosk: Storefront shipped the first generation in VB6 because it was the practical choice at the time (VB.NET/C# weren’t yet publicly available). Rather than rewriting it from scratch later, Kris led a multi-year evolution where new functionality moved into C# components behind stable boundaries, called from the VB6 shell. Over roughly five years, more and more of the kiosk’s real behavior lived in modern, testable C# modules, until VB6 was largely just a thin host while the kiosk’s core logic, integrations, and capabilities ran in C#. That pattern—create seams, move functionality behind interfaces, replace pieces safely—became a repeatable modernization strategy.\n\nKris is strongly biased against “throw it away and start over” rewrites, in line with the classic warning from Joel Spolsky about how rewrites tend to fail in practice. His preference is to modernize by putting proxies/facades around legacy systems (monoliths, old services, old runtimes), then gradually replacing capabilities behind those stable interfaces. That can mean introducing a gateway API over a monolith, extracting a service one workflow at a time, or incrementally migrating a subsystem to a new language/framework while preserving the existing contract. In practice, this approach is how he’s modernized Storefront’s platforms over time: integrating web and mobile experiences with legacy backends, improving maintainability and performance without interrupting revenue, reducing operational costs through safer deployments and fewer brittle dependencies, and building new systems (like kiosk file transfer and payments) that work across both legacy Windows kiosks and modern Android kiosks.\n\nLink referenced: https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/"
    },
    {
      "name": "What were the key responsibilities as Director?",
      "context": "As Director of Software Development (2020–2025), Kris owned company-wide architecture and delivery standards across Storefront’s web, mobile, and retail-device ecosystem, with day-to-day accountability for code quality, technical direction, and shipping outcomes. His responsibilities covered architecture standards and tech stack decisions, prioritizing developer time for maximum business value, and owning incident response when issues were rooted in software (while partnering with infrastructure-focused teammates when problems were primarily server/ops). In practice he was on the hook for uptime and on-call outcomes for code-related production issues, and he consistently drove improvements that made releases safer and faster—moving from slower release cycles earlier on to weekly releases once CI/CD became reliable.\n\nKris’s scope was broad and concrete: he was fully responsible for the Remote Management platform, consumer-facing mobile applications, the web front-end, internal store utilities, and the “personalizer” embedded into external partner sites (notably Kirkland’s). He shared ownership for major legacy and platform pillars including the Windows Kiosk, Android Kiosk, and the Shopify-based SaaS integration—often spearheading initial development and delivery, then handing mature products to other managers once stable and operational. He led through major shifts in team size and company context: at peak, the org included ~15 developers, 4 QA, 4 PMs, and 3 designers; by the final year, it was ~6 developers, 2 QA, 2 PMs, and 1 designer. He was directly involved in hiring, established pairing and code review culture, introduced practices like lunch-and-learns, and worked intentionally to keep team cohesion high after the COVID transition from office-first to mostly remote.\n\nOn product delivery, Kris drove both modernization and new revenue. He led key legacy modernization efforts such as migrating Windows-only imaging services to Linux/.NET Core, and tackled “keep revenue running while changing engines” challenges—most notably evolving the SaaS offering toward a microservices architecture that initially called into the monolith via APIs, then progressively replaced monolith dependencies by integrating directly with the monolith’s database and services in a controlled, phased way. He oversaw and guided shared libraries and platform tooling across C#, TypeScript, and lower-level C components—especially imaging libraries—and owned important integration infrastructure, including monolith integration patterns using the Solace message bus and developer tooling that enabled front-end teams to interact with Solace from the browser.\n\nKris also delivered high-impact partner solutions under tight timelines. A standout example was unblocking an entirely new revenue stream by creating the Kirkland’s personalizer: an embeddable iframe experience that enabled customers to personalize Design Direct print-on-demand products directly on Kirkland’s site, while integrating with partner fulfillment via EDI. He built the initial proof-of-concept over a weekend, demonstrated it to Kirkland’s web team the following week, and drove the project to completion in under three months—turning a partnership opportunity into a shippable, revenue-generating system. On mobile, he owned the strategy shift from white-labeled iOS/Android PhotoSite apps toward a mobile-first PWA, and he led targeted mobile delivery where it mattered—such as the TelCel app for Mexico (Android-first), which supported photo upload, cropping, and payment via TelCel’s SOAP API against user pay-per-use credits, designed intentionally as a simple, low-friction consumer experience."
    },
    {
      "name": "What team size and scope did that role cover?",
      "context": "As Director, Kris’s team scope flexed with the company’s size and business cycle. At peak, he operated within an org of roughly 15 developers, 4 QA, 4 PMs, and 3 designers; in the final year, that condensed to about 6 developers, 2 QA, 2 PMs, and 1 designer. While the broader engineering org could be larger, his direct management/mentorship span was typically up to ~10 developers, with responsibility for hiring, onboarding, pairing and code review culture, and keeping delivery effective as the company shifted from in-office to mostly remote after COVID. He also mentored across a wide spectrum of experience levels—from boot-camp grads with prior careers to highly academic hires (including PhDs) who needed help translating strong technical ability into shipping software in a business environment.\n\nScope-wise, Kris’s remit was genuinely company-wide across web, mobile, and kiosk platforms, but with clear ownership boundaries. He was fully responsible for the Remote Management platform, web front-end, consumer-facing mobile work, store utilities/internal tools, and the embedded “personalizer” used by external partners (notably the Kirkland’s integration). He had shared responsibility for the Windows Kiosk, Android Kiosk, and Shopify SaaS integration work—often spearheading initial builds and early delivery, then transitioning mature product lines to other leaders once stable. Across all of this, his scope included both feature delivery and the platform foundations that made delivery sustainable: core/shared libraries (imaging in C#/TypeScript plus lower-level components), legacy modernization strategy, integration patterns around the monolith (including Solace message bus usage), front-end developer tooling for those integrations, and the CI/CD and release practices that eventually enabled weekly releases when the pipeline became reliable."
    },
    {
      "name": "What consumer-facing mobile apps were delivered?",
      "context": "Kris delivered and led multiple consumer-facing mobile efforts at Storefront and as a consultant, spanning native and cross-platform approaches depending on the business need and timeline. Earlier, Storefront shipped a white-label iOS/Android “PhotoSite” mobile app that covered the core end-to-end photo commerce flow—account/login, photo upload, editing/cropping, ordering, payment, and pickup/fulfillment integration—before the company later consolidated that experience into a mobile-first progressive web app. In his final years, Kris directly created and delivered a TelCel-focused Android app for Mexico (an intentionally Android-first market), designed as a simple, low-friction consumer experience: photo upload, cropping, and payment via TelCel’s SOAP API against the user’s pay-per-use credits.\n\nIn addition to Storefront’s first-party apps, Kris has built and shipped a broad range of mobile applications as a consultant, using Cordova and Flutter as well as modern native stacks and UI frameworks like Jetpack Compose (Android) and SwiftUI (iOS). He’s also worked in React Native where it fit project constraints. That breadth matters because he’s comfortable making the tradeoffs between native quality, development speed, platform access, and long-term maintainability rather than forcing one tool everywhere.\n\nFinally, Kris’s mobile experience isn’t limited to “app screens.” The Android Kiosk program required systems-level Android work: building and supporting a constrained, locked-down device environment with custom OS-level behavior. Storefront created a custom ROM, multiple native services, and even a ROM updater. Kris oversaw that work at the architectural and delivery level—ensuring the platform was operable and maintainable at fleet scale—while other engineers owned portions of the implementation."
    },
    {
      "name": "How were legacy systems modernized during this time?",
      "context": "During Kris’s Director tenure, legacy modernization was treated as a continuous program rather than a one-time rewrite: keep revenue systems running, create safety (tests/CI/observability), and replace components incrementally behind stable interfaces. In practice, that meant modernizing the highest-risk or highest-leverage areas first, while preserving compatibility with long-lived retail deployments and partner integrations.\n\nA core example was the evolution of kiosk and imaging infrastructure. Storefront’s early Windows kiosk stack began in VB6 for pragmatic reasons, but over time Kris drove a careful transition where new functionality moved into C# components called from the VB6 shell—eventually leaving VB6 as a thin host with the real system behavior living in modern, testable modules. That same modernization mindset carried forward into later platform shifts, including migrating Windows-only imaging services to Linux and .NET Core to improve deployability, maintainability, and long-term support.\n\nModernization also meant bridging old and new product generations rather than forcing clean breaks. Kris designed the Kiosk File Transfer and Payment system (Node.js + React) specifically so it could be adopted by both legacy Windows kiosks and modern Android kiosks, enabling a unified customer flow across a mixed fleet. This removed major friction (no phone plug-in), increased kiosk usage significantly, and improved revenue integrity once payment was introduced—without requiring a full replacement of the kiosk stack.\n\nOn the enterprise SaaS side, Kris led the “change engines without stalling the car” approach to moving from a monolith toward a more distributed architecture. The Shopify-oriented SaaS platform started by calling into the monolith through APIs (proxies/facades), then progressively phased those dependencies out by owning more direct integrations and capabilities while still interoperating with the existing database and workflows. Throughout, he emphasized incremental delivery, safe rollouts, and operational tooling—so modernization improved stability and performance rather than creating a risky multi-year rewrite."
    },
    {
      "name": "What is the system prompt used by the chat?",
      "context": "The chat uses the following system prompt: 'You are a professional job fit analyst. Your task is to provide an honest, balanced assessment of how well Kris Erickson's experience and skills match a given job description.\n\nOperating principles:\n- Be objective and honest. Do not oversell or undersell.\n- Base your assessment ONLY on the candidate's actual experience provided in the context.\n- Identify genuine matches where skills and experience align with requirements.\n- Identify genuine gaps where requirements are not met by the candidate's background.\n- Do not fabricate or exaggerate qualifications.\n\nOutput format:\nYou MUST respond with valid JSON matching this exact structure:\n{\n  \"verdict\": \"strong\" | \"moderate\" | \"weak\",\n  \"jobTitle\": \"extracted or inferred job title from the posting\",\n  \"summary\": \"2-3 sentence overall assessment\",\n  \"matches\": [\n    { \"title\": \"Short match title\", \"description\": \"Why this is a match with specific evidence\" }\n  ],\n  \"gaps\": [\n    { \"title\": \"Short gap title\", \"description\": \"What's missing and how significant it is\" }\n  ],\n  \"recommendation\": \"1-2 sentence recommendation for the hiring manager\"\n}\n\nVerdict guidelines:\n- \"strong\": 70%+ of key requirements are met with direct, relevant experience\n- \"moderate\": 40-70% of requirements met, or close matches exist\n- \"weak\": Less than 40% of key requirements met\n\nInclude 3-6 matches and 2-4 gaps. Be specific with evidence from the resume.'",
      "verbatim": true
    },
    {
      "name": "How does the RAG (retrieval) system work?",
      "context": "Simple overview\n\nRAG (retrieval‑augmented generation) means: before asking the LLM to answer, retrieve relevant pieces of your knowledge base and include them with the prompt so the model answers grounded in actual source content. This RAG system uses Cloudflare Workers AI with the BGE-small embedding model to find relevant context, CV data is always included as base context (without embedding search). Additional context can be added and are embedded for semantic search from the questions.json file found at https://github.com/kriserickson/aging-coder/blob/main/api-worker/src/rag-data/questions.json . When a question is asked, the system finds the most relevant context chunks and includes them with the question sent to the LLM. In this system: How it works (step by step)\n\nIngest & chunk\nQuestions are turned into embeddings (while in a real system these would be documents that would be chunked and placed into a vecotr database, we are simplifying things here by keeping the coontext relatively short and not bothering with chunking).\nEmbed\nEach question context is converted into a numeric embedding using Cloudflare Workers AI’s BGE-small embedding model. These fixed-length vectors capture semantic meaning.\nStore index\nEmbeddings are stored in an index in a ValKey (a Redis clone) database for later lookup (we try to keep them in  in-memory but Cloudflare shuts down works often).\nQuery-time flow\nThe incoming question is embedded with BGE-small.\nThe system computes similarity between the question embedding and each document chunk embedding (cosine similarity).\nIt selects the top‑k scoring chunks (and applies any score threshold or exact-match rules).\nThe selected chunks + the always-included CV base context are assembled into the prompt sent to the LLM. This keeps answers grounded in real source content.\nSafety & pragmatics\nThe prompt assembly respects token limits (truncate/merge as needed), respects provenance (cite or attach metadata), and falls back to defaults if no high-confidence chunks are found. For more information see my blog post on: https://agingcoder.com/posts/i-built-an-interactive-cv/"
    },
    {
      "name": "Where did you get the idea for this?",
      "context": "I got the idea of this interactive CV by writing my blog, I frequently create documents, research and pages of writing (and sometimes code) that is never included in the blog post.  Last spring I was thinking about augmenting my blog with a chat interface that could answer questions about my experience and skills, and I realized that a RAG (retrieval-augmented generation) approach would be a great fit.  After loosing my job and sending dozens of resumes into the AI ATS (Applicant Tracking System) machine, I thought I could try to get AI to work with me rather than be the adversary that I was trying to beat to get my resume noticed.  While I had been planning this for a while, Nate Jones YouTube video 'Linked in is Dead'  https://www.youtube.com/watch?v=0teZqotpqT8 inspired me to get this done, as well as gaving me the idea for the Fit Assesment."
    },
    {
      "name": "Where can I find the source code?",
      "context": "The source code for this interactive CV is open source at https://github.com/kriserickson/aging-coder . The blog uses Eleventy (11ty) for static site generation, but you can find the front-end code the `cv` directory and the API code in the `api-worker` directory,  It is using Cloudflare Workers + Hono for the API, and routes LLM model calls through OpenRouter (including OpenAI models). Feel free to fork it or adapt it for your own interactive CV or other RAG apps. Much of the implementation was produced with LLM help but the source code may inspire or provide you a good starting point, but the real work is the content: gathering accurate data about yourself, organizing it into retrievable chunks/Q&A, and iterating on what the system can reliably answer.",
      "verbatim": true
    },
    {
      "name": "Which frontend frameworks are you most experienced with?",
      "context": "Kris has deep, long-running frontend experience across the major SPA ecosystems, with expert-level production work in React (since 2015), Vue (since 2016), and Angular (since 2011—strongest in the earlier generations, with less day-to-day time in the most modern Angular patterns). He’s been building large JavaScript applications since 1999 and has used TypeScript heavily since 2013, so he’s comfortable both shipping quickly and keeping codebases maintainable as they scale. He’s built customer-facing and admin UIs, real-time applications using WebSockets, and multiple Progressive Web Apps (PWAs) where offline/latency and performance characteristics actually matter.)\n\nHe’s also unusually strong in the “front-end systems” side that keeps teams productive: build chains, bundlers, and migration work. Over the years he’s worked extensively with Vite, Webpack, Rollup, esbuild, Gulp, and Grunt, and he’s comfortable diagnosing the hard problems—slow builds, broken dependency graphs, legacy bundling constraints, and incremental upgrades without breaking production. More recently, he’s leaned into SSR and hybrid rendering to address SEO and perceived performance for SPA-heavy products, using frameworks like Next.js and Nuxt (and experimenting with Vite SSR tooling such as vite-ssr/vitess) to get the best of both worlds: modern component-driven development with stronger initial render and indexability.\n\nOutside of production stacks, Kris keeps current by experimenting with newer frameworks in personal projects—most notably Svelte and SolidJS—which helps him evaluate tradeoffs and bring back proven ideas without chasing fads."
    },
    {
      "name": "What is your philosophy on whether something should be done on the frontend vs backend?",
      "context": "In 2000 at Storefront we pioneered what could be done in JavaScript on the frontend by designing very complex programs and playing tricks with the XML request object in IE (the good old days of var xhr = new ActiveXObject('Microsoft.XMLHTTP');.  Ever since then I have had a strong philosophy of pushing as much as possible to the frontend to improve responsiveness and user experience, while keeping security-sensitive and data-intensive operations on the backend.  With modern frameworks and build tools, it's possible to create rich, interactive applications that run efficiently in the browser, reducing server load and latency. However, since I started off as abackend developer, I always consider try to be pragmatic and do what is best for the end-user and factor in issues like SEO, accessibility, and maintainability when deciding where to implement functionality."
    },
    {
      "name": "What build tools have you worked with?",
      "context": "Kris has extensive hands-on experience with frontend build pipelines across multiple generations of the JavaScript ecosystem. He’s worked deeply with Vite for modern dev-server + bundling workflows, and has long-running production experience with Webpack (custom configs, loaders/plugins, multi-app builds, code-splitting, and performance tuning). He’s also used Rollup heavily—especially for libraries and more controlled bundling outputs—and has incorporated esbuild both directly and as a performance accelerator inside other toolchains. Earlier in his career he built and maintained sizable pipelines using Gulp and Grunt, including task automation for legacy apps and gradual migrations to newer tooling. Across React/Vue/Angular projects, he’s comfortable not only “using” these tools but owning the hard parts: diagnosing slow builds, upgrading dependencies safely, managing environment/config differences, and modernizing build systems incrementally without breaking production."
    },
    {
      "name": "Which back-end languages have you used most?",
      "context": "Kris’s core back-end experience is anchored in PHP, C#, JavaScript/TypeScript (Node.js runtime), and Python, chosen pragmatically based on the product stability and deployment constraints. He’s been building server-side systems in PHP since 1998 (including long-running commerce and partner-integrated systems), and has used C# since 2002, later leaning on ASP.NET Core / .NET Core for modern cross-platform backend services—starting around .NET Core 1.1 since 2016. He has also built substantial backend services in the Node.js ecosystem since 2012 (writing JavaScript/TypeScript, using frameworks like Express but has experience with many frameworks like Koa/Hapi/Hono/Meteor,Sails/Restify), and has used Python since ~2022 for automation, AI/ML-adjacent pipelines, and service development where it fit best. Earlier in his career, he also shipped production backend code in Perl and Ruby, which reinforces his strength as a polyglot who can move between ecosystems without losing engineering rigor."
    },
    {
      "name": "REST, GraphQL, or both?",
      "context": "Kris has used both, but he’s used REST far more frequently than GraphQL. When an external platform is clearly GraphQL-first—like the Shopify API (and, in his case, the Facebook API)—he’ll use GraphQL because it tends to provide better granularity, better-supported capabilities, and a cleaner developer experience than the parallel REST surface. In ecosystems that offer both, Kris has generally found the GraphQL implementation to be the more complete and thoughtfully designed option.\n\nWhen building his own APIs, though, Kris is cautious about adding GraphQL because it introduces real complexity and operational tradeoffs. He’s seen this firsthand: early on, an intern built a GraphQL layer for a small slice of Storefront functionality, but because it largely acted as a proxy over existing REST endpoints, it brought performance penalties and made caching harder. Since it didn’t deliver enough unique value relative to the added operational and implementation cost, the team ultimately removed it. That experience reinforced a practical rule: GraphQL is worth it when it unlocks material product or integration wins, but it’s not a default choice.\n\nExamples of “very good reasons” Kris would choose GraphQL when designing an API:\n\nClient-driven data shapes: multiple UIs (web/mobile/kiosk/partner embeds) need different subsets of the same entities, and GraphQL reduces endpoint sprawl and over-fetching.\n\nChattiness and latency pain: a screen currently requires many sequential REST calls; GraphQL can collapse that into a single request when the graph is modeled well.\n\nA strong typed contract is a force multiplier: teams benefit from a schema-first approach, introspection, and type-safe client generation—especially as the surface area grows.\n\nAggregation across services: you need a composition layer that pulls data from multiple backends/services so the client doesn’t have to orchestrate it.\n\nPlatform alignment: the primary platform API you’re integrating with is GraphQL-first (e.g., Shopify), so GraphQL is the most direct and feature-complete route.\n\nIn practice, Kris evaluates GraphQL with an operator’s mindset: can we cache it effectively, can we keep it fast, can we secure it cleanly, and is the added work justified for a small team? If the answer is “no,” REST remains the simpler, more robust default."
    },
    {
      "name": "Messaging/event-driven experience (Solace/Kafka/RabbitMQ)?",
      "context": "Kris is comfortable with event-driven architecture and messaging patterns, with production experience and pragmatic familiarity across multiple brokers. At Storefront, the only message bus used in production was Solace, where he worked with it extensively as part of core platform integration—using messaging to decouple systems, move work asynchronously, and connect legacy and newer components without forcing tight coupling. In addition to that production Solace experience, he’s also explored other brokers in practical contexts: the team ran internal evaluations with Kafka, and RabbitMQ was trialed in the kiosk project (ultimately not becoming the long-term production standard there). Outside Storefront, Kris has used RabbitMQ and BullMQ (Redis-backed queues) in consulting and personal projects, so he’s familiar with the “hands-on” mechanics as well as the architectural tradeoffs—durability vs throughput, ordering, retries/backoff, dead-lettering, idempotency, poison messages, and operational concerns like monitoring and backpressure. Overall, he approaches messaging as a tool for reliability and scale: using events when they reduce coupling and improve resilience, and being explicit about the operational disciplines required to make EDA trustworthy in production."
    },
    {
      "name": "How do you debug production issues?",
      "context": "Kris’s debugging approach is practical and iterative: start with the most direct evidence, get a repro if at all possible, stop the bleeding quickly, then harden the fix so it doesn’t come back. His first move is almost always logs—the lowest-level, most concrete record of what actually happened—paired with whatever context is available from user reports, support tickets, or monitoring alerts. Over time he’s found it critical to maintain a “known failure modes” knowledge base (his own notes plus a shared team wiki) because production issues repeat: the fastest path to resolution is often recognizing a familiar pattern.\n\nTooling-wise, he’s used Sentry, New Relic, Splunk, Kibana/OpenSearch (ELK-style logging), and OpenTelemetry. He values tracing, but he’s also pragmatic about it: OpenTelemetry can produce a flood of data, and his bias is to first identify the simplest concrete symptom (the specific error, request, or workflow that’s failing) before zooming out into distributed traces. For kiosk and device-fleet issues, remote management and telemetry were essential: pulling kiosk logs directly, correlating them with backend logs, and working with QA to reproduce issues reliably when they couldn’t be reproduced locally.\n\nReproduction is a key step in his process. After initial triage, he tries to reproduce the failure personally or through QA and then forms hypotheses grounded in real-world “classic” causes he’s seen repeatedly—time zone and locale bugs across countries, race conditions, caching inconsistencies, concurrency issues, integration drift, and edge-case data. When a fast repro isn’t possible, he focuses on narrowing the scope with additional logging, targeted probes, and carefully chosen test scenarios until the system’s behavior becomes predictable.\n\nWhen it comes to fixing, Kris separates mitigation from resolution. The first goal is to stop the impact without necessarily shipping code: a safe “duct tape” mitigation (cache clear, configuration toggle, a small operational change, a corrective database update, a temporary workflow change) can restore service quickly. Then he moves to a durable code fix that survives the next deploy and prevents recurrence. His “it’s fixed” bar usually includes: the underlying cause addressed in code when appropriate, tests added when feasible, and operational guardrails (alerts, runbooks, or automated checks). If something can’t be reliably tested in code, he prefers an automated verification (e.g., uptime checks) and, if needed, a documented manual checklist until automation is possible.\n\nFinally, Kris treats communication as part of debugging. He aims to share what happened and what was learned—via quick write-ups, incident notes, or lightweight postmortems—so the whole team benefits and recurring issues get faster to diagnose next time."
    },
    {
      "name": "What about API design?",
      "context": "Kris approaches API design as a product and an operations surface, not just a set of endpoints. His default is **REST** with clear resource boundaries and predictable semantics, adding **GraphQL** only when there’s a strong reason (and often because an external platform like Shopify is GraphQL-first). He designs APIs to be easy for clients to use and hard to misuse: consistent naming, stable contracts, and behavior that remains understandable as the system grows across web, mobile, kiosk, and partner integrations.\n\nPractically, that means he pays close attention to the boring-but-critical details that determine whether an API survives in production:\n\n* **Contracts and versioning:** He prefers additive, backward-compatible evolution (new fields/endpoints rather than breaking changes), with explicit versioning when necessary.\n* **Security by design:** APIs are designed with secure defaults—least-privilege access, clear trust boundaries, strong input validation, and consistent handling of sensitive data (PII/payment-related metadata). He’s mindful of common threats (injection, replay, overbroad access, abuse/automation) and builds in protections like scoped tokens, rate limiting, and auditability where appropriate.\n* **Idempotency and reliability:** For any operation that might be retried (network glitches, kiosk connectivity, mobile clients), he designs idempotent workflows and stable request identifiers so retries don’t create duplicate orders, double charges, or inconsistent states.\n* **Performance and caching:** He designs for low-latency client experiences (especially kiosk/mobile), using pagination, filtering, and cache-friendly responses where appropriate—while staying aware of where caching is hard (e.g., highly personalized data).\n* **Operational visibility:** He builds APIs that are debuggable: structured logging, correlation IDs, traceability across services, and clear error responses that help support and engineering isolate issues quickly.\n* **Integration-first mindset:** Because much of Storefront’s success depended on partners, he’s experienced designing APIs and integration surfaces that work with external ecosystems—payments, fulfillment/lab systems, retail workflows, and commerce platforms—where you need to be resilient to upstream changes and partial failures.\n\nWhen the architecture calls for it, Kris also uses **messaging/event-driven patterns** alongside APIs—treating synchronous APIs as the “front door” for real-time needs and events/queues as the backbone for durable, decoupled processing. The result is an API design style that’s pragmatic, evolvable, and grounded in what keeps multi-channel, partner-integrated systems stable over years.\n"
    },
    {
      "name": "Which ML frameworks have you used?",
      "context": "Kris has hands-on experience with PyTorch, OpenCV, Scikit-learn, and Hugging Face Transformers, with a strong bias toward ML that actually ships and improves user workflows. He’s been using computer vision (primarily OpenCV) in production photo systems for 10+ years across multiple platform generations: Windows kiosks, a later Linux/.NET Core imaging service, and Android kiosk services (Java calling into OpenCV C components). That work included practical, customer-visible capabilities like photo enhancement pipelines (including color correction), red-eye reduction, face detection to enable smarter auto-cropping for templated products (e.g., photobooks), and “similar image” grouping to reduce gallery clutter (using a mix of perceptual hashing, color histograms, and capture date/time signals).\n\nOn the modern ML/LLM side, Kris has used PyTorch + Hugging Face Transformers for experimentation and prototyping, including LoRA-style adaptation and instruction-tuning-style experiments, and has built embedding/RAG workflows using transformer-based encoders (e.g., SentenceTransformers as a wrapper over Transformers/PyTorch). He’s also used Scikit-learn extensively for classical ML pipelines—feature extraction, training, evaluation, and clustering—especially when the problem is best solved with lightweight, explainable models rather than heavyweight generative approaches. Importantly, he evaluates ML choices pragmatically: if fine-tuning data, latency, or operational complexity don’t justify it, he’ll prefer strong low-cost foundation models or classical approaches that are easier to run and maintain.\n\nRelated posts on his blog: https://agingcoder.com/posts/experiments-in-supervised-learning/ ; https://agingcoder.com/posts/experiments-in-supervised-learning-part-2/ ; https://agingcoder.com/posts/can-a-tiny-llm-beat-a-supervised-model/ ; https://agingcoder.com/posts/clustering-the-cookbook-a-taste-of-unsupervised-learning/ ; https://agingcoder.com/posts/rag-time-cooking-up-smart-recipe-suggestions/"
    },
    {
      "name": "What AI-assisted coding tools do you use?",
      "context": "Kris has been using AI-assisted coding tools since 2021 and treats them as leverage for faster iteration without lowering engineering standards. His day-to-day toolkit includes GitHub Copilot for steady inline acceleration, and newer IDE/agent workflows such as Cursor and Windsurf-style environments for deeper refactors, codebase exploration, and multi-step tasks. He also uses command-line and agent-oriented tools—including Claude Code, OpenCode, Codex CLI, AntiGravity, and KiloCode—depending on the job: quick one-off transformations, repo-wide changes, test generation, documentation drafts, and implementation scaffolding.\n\nHe champions adopting these tools in a way that improves delivery and code quality rather than creating noise: keeping changes small and reviewable, insisting on tests/linters, validating edge cases, and treating generated output as a first draft that still needs experienced review. The result is higher throughput on routine work (boilerplate, refactors, migrations, glue code) while preserving maintainability, correctness, and operational reliability."
    },
    {
      "name": "How do you feel about AI, and its impact on software development?",
      "context": "AI is going to create a lot more software, but it still needs an experienced hand at the tiller. Kris is enthusiastic about the leverage—especially for proof-of-concept demos, interactive prototypes, documentation, and test scaffolding—but he’s wary of “YOLO vibe-coding into production.” He’ll absolutely let AI help with sensitive areas too, but only when the design is thought through upfront and the output is treated like untrusted code that must be audited: small diffs, careful review, and a real quality bar.\n\nHis biggest reservations are that today’s tools still struggle with truly complex systems, and that the combination of security footguns + human overconfidence is dangerous—especially as people start shipping code they don’t fully understand. That ties directly into his concern about skill atrophy: used well, AI could accelerate learning, but used lazily it can produce cargo-cult programmers who can assemble systems without grasping the failure modes.\n\nBecause of that, Kris’s workflow is deliberately conservative even when AI writes a large percentage of the code. His guardrails are non-negotiable: linting, unit tests plus e2e coverage, keeping changes small and reviewable, and real code review (including reviewing tests more closely than most people review feature code). He prefers refactors that are backed by static analysis where possible, and for scaffolding he often prefers modern CLIs because they tend to pull in current libraries and current patterns rather than stale defaults.\n\nHe’s also actively evaluating the shift from IDE-based assistants to CLI agents. He’s not fully decided yet, but the CLI approach is starting to win him over—especially for repository-wide work and workflow automation—while still insisting on reviewing every diff and keeping engineering discipline around the results.\n\nHis outlook is that the industry will see more output and more bugs in the near term: faster shipping cuts both ways. He expects an inflection point—either models become good enough that the “experienced hand” requirement shrinks substantially, or a high-profile failure (security, compliance, or systemic reliability) forces teams to slow down and formalize stronger safeguards."
    },
    {
      "name": "What native mobile experience do you have?",
      "context": "Kris has substantial native mobile experience on both major platforms, plus the “systems-level” Android work that most mobile developers never touch. On **Android**, he’s shipped production apps in **Java and Kotlin**, and he’s comfortable in modern Android UI with **Jetpack Compose** as well as the older View-based world. On **iOS**, he’s built native work in **Swift** and is comfortable with **SwiftUI** for modern declarative UI. He’s also delivered cross-platform apps where it made sense (e.g., **Flutter, Cordova, React Native**), but his native background means he can drop down to platform APIs when performance, device capabilities, or reliability demand it.\n\nBeyond typical consumer apps, Kris’s native experience includes deep involvement in the **Android Kiosk** platform, which required digging into Android at the OS/device level: operating in locked-down retail environments, integrating tightly with device hardware, and supporting kiosk-specific behavior through native services. Storefront created a **custom ROM**, multiple **native background services**, and even a **ROM updater** to manage fleet updates; Kris oversaw that work architecturally and from a delivery standpoint (even when he wasn’t the person writing every component), ensuring it was operable and maintainable at scale.\n\nOn the product side, he led delivery of consumer-facing mobile experiences including a TelCel-focused **Android** app for Mexico (Android-first market) that handled **photo upload, cropping, and payment via TelCel’s SOAP API** against user credits, and earlier white-label iOS/Android app work that covered the core photo-commerce flow (upload, edit, order, pay, fulfill) before the company shifted that experience to a mobile-first web/PWA approach.\n"
    },
    {
      "name": "Which cross-platform tools have you used?",
      "context": "Kris has used several cross-platform mobile stacks in real projects and consulting work, and he treats them as pragmatic tools—not ideology. His primary cross-platform experience includes **Cordova** (for web-to-mobile packaging and rapid delivery when the UI is largely web-based), **Flutter** (for higher-performance, more native-feeling cross-platform apps), and **React Native** (where it fits team skill sets and ecosystem needs). He’s comfortable with the typical cross-platform tradeoffs—plugin availability, platform quirks, performance hot spots, app size, build/release complexity—and because he also has strong native Android (Java/Kotlin/Jetpack Compose) and some iOS (Swift/SwiftUI) experience, he can drop down to native modules when a cross-platform layer hits a wall."
    },
    {
      "name": "Android or iOS preference?",
      "context": "Kris is comfortable building for both Android and iOS, but he’s personally more of an Android-first person day to day—and that has naturally influenced where he’s spent more hands-on time and what he reaches for first when prototyping or dogfooding mobile work. He did use an iPhone in the early days (3G → iPhone 4 era https://agingcoder.com/posts/switching-to-android-6-months-later ), then switched and has written about that transition and what he likes about Android as a platform.\n\nFrom a development standpoint, his “preference” is mostly practical: he biases toward Android when the work involves deeper device integration or systems-level constraints (kiosk/managed device fleets, background services, custom device behavior), where he has significant experience. For consumer apps, he’ll prioritize the market and user base over personal preference (e.g., Android-first delivery when the target market is overwhelmingly Android).\n\nTooling-wise, he’s historically had a dislike for Xcode  https://agingcoder.com/posts/coding-like-its-1999/ —he’s described it as feeling like stepping back in time—and while he’ll grudgingly admit it’s improved, it can still remind him of the bad old Eclipse days."
    },
    {
      "name": "Which databases are you most familiar with?",
      "context": "Kris is strongest in relational databases that sit at the core of revenue systems—especially MySQL and PostgreSQL—covering schema design, indexing, query tuning, migrations, and the operational realities of keeping reporting and transactional correctness trustworthy at scale. He’s also used SQLite where embedded/local persistence is the right tradeoff. On the NoSQL side, he has practical production experience with MongoDB for document-oriented workloads, Redis for caching and fast ephemeral state (and queue-like patterns in some projects), and CouchDB where replication/offline-friendly document storage is a good fit. Across these, he’s comfortable choosing between SQL and NoSQL based on durability, consistency needs, operational simplicity, and how the data will actually be used in production."
    },
    {
      "name": "Experience with Redis?",
      "context": "Kris has solid hands-on experience with Redis (and Valkey) as both a cache and a lightweight infrastructure component in production systems. He’s used it alongside MySQL/PostgreSQL for performance and scalability—caching expensive reads, reducing database load, and smoothing traffic spikes—while being careful about the usual gotchas (cache invalidation, TTL strategy, stampedes, and consistency tradeoffs). He’s also used Redis in patterns beyond “simple caching,” including ephemeral state, coordination primitives, and queue-like workflows (e.g., BullMQ-style job processing in consulting/personal projects). In addition to Redis/Valkey, he’s worked with Memcache/Memcached in earlier systems, and is comfortable choosing between them based on operational needs, data structures required, persistence/replication expectations, and team familiarity."
    },
    {
      "name": "SQL or NoSQL preference?",
      "context": "Kris is pragmatic about SQL vs NoSQL, but his default bias is PostgreSQL or MySql: for a huge range of products it “just works,” and it’s usually the fastest path to a reliable system with the fewest long-term surprises. Unless there’s a clear reason to introduce something else—hard scale/cost constraints, extreme write/read patterns, specialized querying needs, offline/replication requirements, or a document/key-value model that materially simplifies the product—he prefers to stick with a strong relational core (often Postgres) and layer in complementary stores (Redis for caching/ephemeral state, MongoDB/CouchDB when document/replication semantics are genuinely needed). In short: start with what’s robust and boring, and only add NoSQL when it earns its complexity."
    },
    {
      "name": "What development methodologies do you prefer?",
      "context": "Kris prefers pragmatic Agile with a strong Lean/DevOps bias: short feedback loops, small batches, and shipping increments that can be validated quickly in production. In practice that means breaking work into vertical slices, keeping scope tight, and prioritizing outcomes (customer value, reliability, revenue impact) over process ceremony. He’s comfortable with Scrum-style planning when it helps coordination, but he’s equally happy with a Kanban/flow approach for operational teams and continuous delivery environments—especially once CI/CD is strong enough to support frequent releases (he’s run teams where weekly releases were realistic once the pipeline and quality gates were in place).\n\nAcross methodologies, his non-negotiables are: clear prioritization with stakeholders, disciplined code review, tests where they matter (unit + end-to-end for critical flows), and strong observability to diagnose issues quickly. He also emphasizes team sustainability—protecting focus time, reducing thrash, and investing in documentation/lunch-and-learns—so teams can move fast without burning out or degrading quality."
    },
    {
      "name": "Experience with TDD?",
      "context": "Kris understands and values TDD, and he has tested using it on smaller projects and in focused areas where a strict Red/Green/Refactor loop makes sense. However, he hasn’t practiced full, end-to-end TDD as the dominant methodology across large professional codebases. In real-world enterprise and retail systems—especially legacy-heavy platforms—his approach has been more pragmatic: add tests where they buy real safety, grow coverage around critical paths, and use characterization tests to make changes confidently in existing code. He consistently relies on unit tests plus end-to-end tests, CI quality gates, and disciplined code review to get the primary benefits people seek from TDD (confidence, regression prevention, safer refactoring) without forcing a rigid process where it doesn’t fit."
    },
    {
      "name": "How do you approach code reviews?",
      "context": "Kris treats code review as both a quality gate and a team-development tool. As a Director and senior engineer, he’s established review practices that prioritize correctness, maintainability, and operational safety—while also making reviews something people don’t dread.\n\nHis style is constructive and collaborative rather than harsh. He aims to give clear, actionable feedback without creating defensiveness, and he often frames comments as questions (“What do you think about…?”, “How will this behave when…?”) to encourage good decision-making and shared ownership instead of dictating solutions. He’s deliberate about balancing critique with recognition: he calls out what’s done well—clean structure, good naming, thoughtful edge-case handling—so the review feels fair and motivating, not like a hunt for mistakes.\n\nKris also tries to make every review worth the author’s time by imparting a small piece of knowledge when possible: pointing out a safer pattern, a simpler approach, an operational gotcha, or a testing improvement. He doesn’t phone it in—if he’s approving, it’s because he’s actually read the diff, thought through failure modes, and checked that the change fits the architecture and team conventions. The result is a review culture where quality rises over time and engineers learn, rather than merely passing or failing a gate."
    },
    {
      "name": "What CI/CD experience do you have?",
      "context": "Kris has extensive, hands-on CI/CD experience across GitHub Actions, GitLab CI, and Jenkins, and has used CI/CD as a core lever to make teams faster without sacrificing quality. He’s built and maintained pipelines for multi-language, full-stack systems (TypeScript/Node, PHP, C#/.NET, mobile tooling, and supporting services), including monorepo-style workflows, repeatable builds, and reliable release processes.\n\nOn the build and packaging side, he’s comfortable with container-based pipelines using Docker, and has used tools like Kaniko to build container images safely in CI environments without requiring privileged Docker. On the deployment/orchestration side, he has real Kubernetes experience and has shipped systems using Helm charts and Kustomize to manage environment-specific configuration and deployments.\n\nKris’s pipelines typically include the practical quality gates that keep production stable: linting/formatting, unit tests, end-to-end tests for critical flows, artifact versioning, and staged rollouts where appropriate. As Storefront’s pipelines matured and reliability improved, this enabled a shift toward faster, safer delivery—up to weekly release cadence—while keeping production risk under control.\n\nHe’s also comfortable wiring CI/CD into operational needs (release verification, smoke checks, and ensuring the right build artifacts and metadata are available for debugging), and he’s explicit about what he *hasn’t* done: he’s not positioning himself as a Terraform/IaC-from-scratch specialist, but as an engineer/leader who can build, run, and continuously improve real CI/CD systems that ship software reliably."
    },
    {
      "name": "Experience with Kubernetes?",
      "context": "Yes—Kris has hands-on Kubernetes experience in production contexts, using it as the operational foundation for running and deploying services reliably. He’s worked with Kubernetes alongside Docker-based build and deployment workflows, and is comfortable with the practical day-to-day concerns: configuring deployments and services, managing environment-specific settings, rolling updates, and diagnosing issues when things don’t behave as expected.\n\nHe’s also used the common ecosystem tools that make Kubernetes workable at scale, including Helm charts for packaging/releasing applications and Kustomize for managing overlays and per-environment configuration. In CI/CD, he’s built containerized pipelines that produce deployable artifacts and integrate cleanly with Kubernetes-based delivery.\n\nKris tends to pair Kubernetes with a production mindset—observability, safe rollouts, and clear operational ownership—especially in systems that also rely on asynchronous/event-driven patterns (e.g., message bus integrations) where reliability and backpressure handling matter."
    },
    {
      "name": "Which CI/CD tools have you used?",
      "context": "Kris’s CI/CD experience spans multiple “generations” of build and release tooling, starting well before modern hosted pipelines. Early on, he used tools like Visual Build Pro and even built a custom buildbot-style system from scratch to make Windows Kiosk builds reproducible—removing the risk of releases depending on the quirks of an individual developer’s machine and ensuring consistent, repeatable outputs for retail deployments.\n\nAs the industry matured, he moved into the Jenkins era (and later TeamCity for a period), where CI became a key driver of delivery speed and confidence. With Jenkins, he helped push automation beyond compile-and-package: Jenkins orchestrated Selenium-based end-to-end testing for the PhotoSite, which materially improved confidence in releases and helped the team move from monthly/quarterly release cycles to a cadence where weekly production releases—and even daily staging deployments—were realistic.\n\nFrom there, the pipeline evolution continued into GitLab CI, where he built containerized workflows (Docker/Kaniko) that produced deployable images for Kubernetes environments—bringing modern, repeatable build artifacts and more consistent deployments across environments.\n\nIn addition to Storefront’s primary toolchains, Kris has also used GitHub Actions and Travis CI in consulting work and side projects, and he’s comfortable adapting to whichever CI system fits the organization—as long as it supports fast feedback, meaningful quality gates, and reliable releases."
    },
    {
      "name": "What are your feelings about DevOps practices?",
      "context": "Kris is strongly supportive of DevOps practices, but in a pragmatic, outcomes-first way: DevOps isn’t “tools” or a job title to him—it’s the discipline of making software shippable and operable. He believes the best product teams take shared ownership of delivery and production reliability, with clear handoffs where specialized infrastructure expertise is needed, but without throwing problems over the wall.\n\nIn practice, his DevOps philosophy centers on a few repeatable habits: automate the path to production (CI/CD, reproducible builds, scripted deployments), keep changes small and frequent so failures are recoverable, and build strong observability so teams can diagnose issues quickly without guesswork. He’s seen first-hand that reliable CI and end-to-end testing can change delivery economics—enabling a shift from slow, risky releases (monthly/quarterly) to weekly production releases and daily staging deployments.\n\nHe’s also particularly motivated by DevOps where it reduces real operational cost and downtime—especially in retail/kiosk environments where field visits are expensive. Remote management, safe rollout mechanisms, and actionable monitoring aren’t “nice to have” in that world; they directly protect revenue. Overall, Kris likes DevOps practices because they make teams faster, calmer, and more trustworthy: fewer heroics, more predictable delivery, and systems that can be improved continuously without risking the business."
    },
    {
      "name": "Which are your strongest languages?",
      "context": "Kris’s strongest languages are TypeScript/JavaScript (especially for frontend work and Node.js-based services), C#, and PHP—these are the ecosystems where he has the deepest production mileage and has led large, long-lived systems. He’s also very effective in Python (particularly for modern tooling and AI/automation workflows) and is comfortable shipping native work in Kotlin/Java on Android and Swift on iOS when projects call for it. More broadly, he’s a proven polyglot who can ramp quickly in new languages and frameworks and loves doing so, but his “most battle-tested” strengths are TypeScript/JavaScript, C#, and PHP."
    },
    {
      "name": "Any unusual or niche languages?",
      "context": "Yes — Kris co-developed and maintained a niche internal language for nearly two decades: **SFML (Storefront Markup Language)**. SFML was a custom templating / composition language used to build and customize Storefront’s white-label e-commerce and photo-commerce sites without forking the entire codebase. It looked like tag-based markup, letting page authors express commerce and UI intent with high-level widgets and loops (conceptually similar to early ColdFusion/JSP-era tag libraries), e.g. product/result rendering and cart composition via tags like `<sfml.cart> ... <sfml.cart_item> ... </sfml.cart_item> ... </sfml.cart>`.\n\nUnder the hood, SFML wasn’t “just markup.” It compiled into runtime output and was backed by an embedded, **Turing-complete expression and scripting language** the team referred to as **ML**. ML supported variables, arrays/hashes, loops, conditional logic, regex operations, string functions, and higher-level helpers (e.g., `join`, `split`, `keys`, `reg_match`, `reg_replace`). SFML tags could declare attributes and generate code based on parsed expressions — for example, tags like `sfml.if` implemented conditional evaluation with options like case-insensitive matching, feature gating, and permission checks, while tags like `sfml.set` parsed expressions and assigned values into scoped variable dictionaries.\n\nKris implemented the language tooling using classic compiler techniques (Flex/Bison — Lex/YACC style) in C, and he owned the evolution of the parser, tag system, expression engine, and extensive test coverage for the language runtime. The net effect was a powerful internal DSL that enabled rapid partner customization and long-term maintainability at scale: retailers could have distinct experiences and rules, while the platform remained one coherent product instead of dozens of divergent forks."
    },
    {
      "name": "How do you approach learning new languages?",
      "context": "Kris learns new languages the same way he learns any new tool: by shipping something real, then deepening the fundamentals once the first version works. He typically starts with a small but end-to-end goal (a feature, service, or prototype) so the language is learned in context—build tooling, dependency management, testing, debugging, and deployment—rather than as isolated syntax.\n\nHe anchors on the language’s “idioms” early: how it wants code to be structured, how errors are handled, how async/concurrency works, and what the standard libraries do well. He’ll then compare those idioms to the patterns he already knows (TypeScript/JS, PHP, C#, etc.) to avoid writing ‘old-language code in a new language.’\n\nKris also leans on strong feedback loops: linters/formatters, type systems when available, unit tests, and quick iteration in a REPL or scratch project. If the language is being introduced into an existing system, he prefers to start at the edges—small services, tooling, or isolated components—so the team can learn safely without destabilizing revenue-critical code.\n\nFinally, he’s pragmatic about mastery: he doesn’t try to memorize everything up front. He focuses on the 20% that unlocks productive work, uses documentation and examples heavily, and builds confidence through repeated production use—then circles back to deepen performance, tooling, and advanced language features once it’s proven valuable."
    },
    {
      "name": "What is the Storefront E-Commerce Platform?",
      "context": "The Storefront E-Commerce Platform is a long-running, white-label enterprise commerce system Kris helped architect and build starting in 2000 (evolving from an initial 1999 consulting engagement). It became the foundation for Storefront’s shift into photo commerce—supporting online photo ordering, photo-product customization, pricing/promotions, order state, and fulfillment integration across both web and in-store retail workflows.\n\nIn practice it wasn’t “just a website.” It supported multi-channel customer journeys (order on the web, print/pick up in-store, and web ↔ kiosk continuity), retailer-specific rules and branding, and the operational realities of high-volume photo finishing. The platform has remained operational for 25+ years and has powered photo product ordering for 10+ major retail partners, including Rite Aid, Fred Meyer, King Soopers, Duane Reade, Smith’s, Benavides, Fuji Mexico, Costco Mexico, London Drugs, and Dodd’s Photo. Its longevity reflects Kris’s strength in building systems that can evolve—through new product lines, new device generations, and major technology shifts—without breaking revenue or partner trust."
    },
    {
      "name": "What was your role in the development of the Storefront E-Commerce Platform?",
      "context": "Kris was a long-term lead contributor and technical co-lead on the Storefront E-Commerce Platform from its early “generic commerce” phase through its evolution into a large-scale, white-label photo commerce system. In the earliest era, the team extended the technology from the Elgrande site into multiple e-commerce properties (toys, drug stores, etc.) and then formalized that work into Storefront.com as a configurable platform.\n\nA centerpiece of Kris’s contribution was creating and owning the platform’s customization layer: SFML (Storefront Markup Language). SFML was a server-side templating/configuration language in the style of early web templating systems (e.g., ColdFusion/JSP-era patterns). Kris implemented SFML using Bison/Flex (YACC/Lex) in C, and then maintained and evolved it for nearly 20 years. SFML became the mechanism that enabled white-labeling at scale—partner-specific site behavior, layouts, and rules—without forking the entire codebase.\n\nAs the business pivoted into photo commerce—starting with an early Windows XP-era photo ordering effort for London Drugs, then expanding into a full photo and photo-product ordering site—Kris’s role centered on the customer-facing experience and the technical foundations required for photo product customization. Pre-photo, he owned much of the frontend/user experience up through checkout and shared overall leadership with another senior engineer. He generally handed off responsibility once the customer left the cart, so payment processing, taxes, shipping, and most fulfillment logic were primarily owned by others (though he collaborated across boundaries as needed).\n\nIn the photo era, Kris took primary ownership of imaging and product/campaign complexity: photo upload and preview workflows, image transforms and rendering, catalog and product rules (templates, variants, sizes, multi-surface products, pricing constraints), and the imaging endpoints that made customization possible. He also took over and modernized Storefront’s proprietary imaging engine—originally written in C—porting it to C#, and later (around 2023) moving major portions into JavaScript to bring key imaging capabilities closer to the frontend and improve the interactive customer experience.\n\nOver 25+ years, 30+ engineers contributed to the platform, but Kris remained one of the consistent technical anchors—carrying forward deep context, evolving the stack over time (PHP + custom JS frameworks → jQuery → Angular → Vue), and helping the platform scale to real retail volume. At peak, major partners like Rite Aid were doing on the order of ~10,000 orders/day in the 2009 era (often pay-in-store), reflecting the platform’s role as a revenue-critical backbone rather than a one-off website."
    },
    {
      "name": "Tell me about the E-Commerce Platform architecture",
      "context": "The architecture was a configurable, multi-tenant platform with a shared core and a customization layer (SFML) that allowed per-retailer rules and layouts. It used modular services for catalog, fulfillment, and imaging, with clear integration points for partner-specific adapters. This allowed the platform to evolve incrementally while serving many retailer-specific configurations."
    },
    {
      "name": "What long-running projects were maintained?",
      "context": "Kris spent much of his career maintaining and modernizing long-lived, revenue-critical systems—work that’s less about “keeping the lights on” and more about evolving platforms safely while they continue to run at scale.\n\nThe core was the Storefront white-label E-Commerce / Photo Commerce Platform (2000–present), which grew from early generic commerce roots into a multi-tenant retailer platform supporting photo ordering, photo products, and print-on-demand workflows across major partners. It evolved through multiple frontend eras (custom JS → jQuery → Angular → Vue/mobile-first), while keeping stable order/catalog rules and partner integrations intact.\n\nAlongside the web platform was the Windows Photo Kiosk (launched 2005), which had its own long lifecycle and required continual hardening, peripheral support, and UX iteration in real retail environments. Kris helped drive the “make it rock-solid” mindset early on, and the kiosk platform continued to evolve through years of production use—processing millions of prints and supporting high-volume retail programs.\n\nA third long-running pillar was imaging: proprietary photo-processing services and libraries that powered enhancement and product workflows (e.g., color correction, red-eye reduction, face detection/auto-cropping, and “similar image” grouping). These components survived multiple platform generations and were modernized over time—moving from lower-level C code into C# services, later into Linux/.NET Core deployments, and even into browser-side JavaScript in later years to reduce upload friction and speed the customer experience.\n\nFinally, the Remote Management and Monitoring Platform became a durable control plane for a large device fleet. What began as kiosk monitoring grew into a system capable of managing tens of thousands of devices and high request throughput, enabling remote updates, health telemetry, issue triage (down devices, out-of-paper, stuck states), and analytics on customer abandonment points. It expanded beyond kiosks into lab/print systems and newer device generations.\n\nThe unifying theme across these projects is how they were maintained: Kris favored incremental modernization—adding seams, proxies, and replacement components over time—so the business could keep revenue running while the “engine” was improved underneath. That approach avoided rewrite risk, kept partners stable, and allowed the platform to adapt repeatedly as retail and consumer behavior changed."
    },
    {
      "name": "How has the Storefront E-Commerce Platform evolved over 25 years?",
      "context": "The Storefront E-Commerce Platform started around 1999–2000 as a consulting-built commerce system and quickly evolved into a configurable, white-label platform. In the early 2000s it expanded from “generic commerce” into photo commerce after building an online photo ordering flow for London Drugs in the Windows XP era—work that grew into a full photo and photo-product ordering experience and ultimately shaped Storefront’s business for the next two decades.\n\nOver the years, the platform evolved in several major waves rather than a single rewrite. Early on, it relied on a custom presentation and business-logic layer (SFML, Storefront Markup Language) that enabled rapid iteration across retailer-specific storefronts while keeping a shared core. Frontend technology modernized repeatedly as the web changed: custom JavaScript patterns gave way to jQuery-era approaches, then to SPA frameworks (Angular), and later to Vue for modern, maintainable frontends. As customer expectations shifted from desktop to mobile, the customer experience moved toward mobile-first web patterns, and the broader ecosystem incorporated native mobile applications where it made sense for specific partners and markets.\n\nThe platform also expanded well beyond “a website.” It became the web half of a multi-channel commerce system tightly integrated with in-store kiosks and retail fulfillment. This meant the platform had to support mixed customer journeys (start online, pick up/print in-store; start in-store, finish online), consistent catalog and pricing rules across channels, and the operational plumbing required for retailers: stable order state, reporting, and integrations into lab/print workflows.\n\nOn the backend, Storefront repeatedly modernized without breaking revenue. Core services and APIs were extended and refactored as new product lines appeared (photo products, print-on-demand), and as integration needs grew (partner-specific plugins, third-party systems, and messaging patterns such as Solace for cross-system coordination). Imaging capabilities also evolved over time—moving from server-side processing toward more browser-side capabilities in later years to improve responsiveness and reduce unnecessary upload/roundtrip friction.\n\nIn the later stage of the platform’s life, the team began shifting specific capabilities toward more service-oriented architecture where it delivered leverage: distributed components and integrations that could evolve faster than the monolith, including e-commerce integrations (notably Shopify) and partner-embedded customization experiences. Across all of this, the defining trait of the platform’s evolution is continuity: it stayed in production while being modernized in layers—new frontends, new channels, new services, new integrations—without “stop-the-world” rewrites that would have jeopardized long-running retailer programs."
    },
    {
      "name": "Which retailers use it?",
      "context": "The Storefront E-Commerce Platform serves 10+ major retailers including Rite Aid, Costco Mexico, Fred Meyer, Smiths, Duane Reade, King Soopers, London Drugs, Benavides, and Dodd's Photo."
    },
    {
      "name": "What was the Android-based platform project and its impact?",
      "context": "The Android-based platform modernized the kiosk and device fleet strategy by moving to a contemporary, maintainable runtime that supported modern hardware, background services, and easier OTA updates. The project expanded capabilities (better imaging, background sync, and improved security), simplified maintenance across new devices, and helped the product line remain competitive and deployable with lower field-service overhead."
    },
    {
      "name": "Tell me about the kiosk system and its impact",
      "context": "Storefront’s Windows Photo Kiosk launched in 2005 and became a core pillar of the company’s photo-commerce business. Kris helped spearhead the kiosk program from its early development and served as lead architect through the formative years, building a retail-hardened product that had to work reliably in messy real-world conditions: unpredictable peripherals, weird memory cards, slow kiosks, flaky store networks, and customers who abandon instantly if anything feels confusing or broken.\n\nThe kiosk mattered because it put photo ordering directly into stores at the moment digital photography was exploding. The platform processed millions of prints per year and supported major retail photo finishing programs across Canada, the U.S., Mexico, and parts of Europe. In particular, Rite Aid’s photo finishing business peaked at roughly ~$1B per year in annual sales, and Storefront’s web+kiosk ecosystem captured a meaningful share of that volume through both in-store kiosk ordering and web ordering that flowed into in-store printing/pickup.\n\nA key impact was multi-channel continuity: revenue wasn’t just “kiosk or web.” It was often both. Roughly half of orders were kiosk and half web, and many customer journeys crossed channels (start on the web, print at the kiosk; start in-store, complete later online). Making that work required consistent catalog rules, pricing/promotions, shared order state, and reliable fulfillment handoffs to lab/print systems—hard integration work that Kris helped drive and sequence over years.\n\nOperationally, the kiosk program forced serious production ownership. Kris helped lead the capabilities that made a kiosk fleet operable at scale: remote monitoring and log retrieval, visibility into real retail failure modes (down devices, out-of-paper, stuck states), and a path toward remote updates so fixes didn’t require expensive in-store visits. That shift mattered financially—early in the Rite Aid rollout, the kiosk installation/servicing vendor reportedly earned ~2× what Storefront earned on kiosk software because changes required truck rolls. Remote update/management reduced that burden and improved uptime.\n\nThe kiosk platform also evolved with consumer behavior: as phones replaced removable media, Storefront introduced barcode-based phone-to-kiosk transfer that removed major friction and drove measurable adoption lift, and later extended the same secure session approach into phone-based payment to reduce shrinkage and avoid kiosk payment hardware.\n\nNet impact: the kiosk wasn’t just a UI—it was a long-running, revenue-critical retail platform that drove large-scale photo commerce, improved customer convenience, reduced operational cost through fleet management, and strengthened partner trust through reliability and better transaction visibility."
    },
    {
      "name": "What technologies were used?",
      "context": "Storefront’s kiosk + web ecosystem was built as a multi-generation platform, so the “tech used” depends on the era and component—but the consistent theme was pragmatic engineering for retail constraints.\n\nOn the Windows Photo Kiosk side, the earliest kiosk implementation was built in VB6 (chosen because it was the best available option at the time—before VB.NET/C# were broadly viable). Over the following years, the kiosk was progressively modernized by moving more and more functionality into C#/.NET components, with VB6 eventually becoming mostly a thin shell that hosted C# components controlling the real behavior. The kiosk ran primarily on Windows XP in early deployments, later supporting newer Windows versions as retail hardware evolved.\n\nThe kiosk integrated deeply with retail hardware and local services: touchscreen UI, removable media readers (and later phone-transfer workflows), local printers and lab systems, plus peripherals and device-control layers that required defensive programming and extensive error handling. As the platform matured, a large part of its “technology stack” was operational infrastructure: remote monitoring/log retrieval, remote configuration, and update mechanisms designed to keep thousands of kiosks supportable without constant in-store service visits.\n\nOn the web and service side, Storefront’s platform used a long-running backend core heavily in PHP, with a custom templating/runtime layer (SFML / Storefront Markup Language, backed by a Turing-complete ML language) that enabled rapid white-label customization for many retailers. Frontend technology evolved repeatedly as the industry shifted: custom JavaScript frameworks gave way to jQuery, then Angular, and later Vue for modern SPAs and mobile-first experiences.\n\nFor integrations and distributed components, the ecosystem included service layers in C#/.NET (later .NET Core on Linux for parts of the imaging stack), Node.js/TypeScript for newer user-facing flows (notably the kiosk file-transfer + payment system built with Node.js + React), and messaging/event integration via Solace for coordinating between systems. Imaging and photo-processing technologies spanned lower-level code (including C), C# services, OpenCV-based computer vision across multiple platforms, and later browser-side JavaScript image processing to reduce upload friction and speed up personalization workflows.\n\nIn short: the kiosk itself was a Windows/VB6-to-C#/.NET evolution tightly integrated with retail hardware and remote fleet operations, while the broader Storefront platform combined PHP + SFML, modern JS frontends (Angular/Vue), Node/React for newer flows, C#/.NET Core services for shared capabilities, and Solace-based integration patterns to hold the ecosystem together."
    },
    {
      "name": "What was the history of the Kiosk?",
      "context": "Storefront’s kiosk story grew out of the early 2000s shift into online photo ordering: once the web platform proved there was real demand, the next step was bringing photo ordering into stores as a self-serve experience. The first Windows kiosk was written in VB6 (a pragmatic choice before .NET was ready), and an early public milestone was entering the PMA (Photographic Marketing Association) kiosk competition in Las Vegas. That first year the kiosk placed last because it was unstable and crashed frequently. The following year, the team learned the right lesson: rather than cramming features until the last minute, they imposed a hard feature freeze well before the show and spent the final stretch on stability, polish, and “try to make it crash” testing (odd SD cards, broken media, weird edge-case images, device disconnects). The result was a dramatic turnaround—Storefront’s kiosk won most of the major awards, and it continued to perform strongly in subsequent years.\n\nAs .NET matured, the Windows kiosk was modernized incrementally rather than rewritten: over the next several years, more and more functionality moved into C# components while VB6 gradually became a thin shell hosting the newer code. That Windows kiosk platform then ran in production for roughly 15 years, evolving across Windows generations and retail hardware, before eventually being replaced by the Android kiosk line.\n\nThe kiosk platform also expanded beyond photo printing. Storefront built a “multifunction kiosk” variant that included a ringtone kiosk and a music kiosk (burning CDs and even uploading songs to iPods), and also supported internet-kiosk style experiences depending on deployment. That product line was sold into unexpectedly diverse environments—from McDonald’s locations in Germany to U.S. Air Force bases—through partner sales channels including Kis Kiosks.\n\nOver time, as smartphone behavior displaced removable media, the kiosk experience evolved again via barcode-based phone-to-kiosk file transfer (driving a measurable usage lift) and later phone-based payments to reduce friction and shrinkage. Across all generations, the consistent thread in the kiosk’s history was retail reality: stability, operability, and continuous incremental modernization mattered more than flashy feature checklists."
    },
    {
      "name": "How did the kiosk file transfer and payment system work?",
      "context": "The file transfer + payment system was built to remove two of the biggest kiosk pain points: (1) getting photos onto the kiosk without cables/USB media, and (2) taking payment without forcing credit-card entry on a public kiosk or installing expensive payment hardware.\n\nFile transfer: phone-to-kiosk session handoff\n\nThe core idea was a shared “session” between the kiosk and the customer’s phone. On the kiosk, the user would start a transfer session and the kiosk would show a barcode/QR (and/or a short code). The customer would scan the barcode with their phone (or enter the code), which linked the phone to that specific kiosk session. Once linked, the phone uploaded photos over the network into that session instead of physically connecting to the kiosk.\n\nOn the backend, uploads were stored in a transient, time-limited staging area keyed to the session. The kiosk then pulled (or was notified about) newly uploaded assets and made them available locally in the kiosk UI for browsing, editing, and product creation. In practice, this replaced “plug in a phone / mount storage / import” with a much more reliable and user-friendly flow that matched the smartphone era. The business outcome was clear: once customers didn’t need to plug their phones in anymore, kiosk usage increased by ~50%.\n\nPayments: reuse the session for a secure phone-based checkout\n\nAfter the transfer workflow proved the session handoff worked well, Kris realized the same infrastructure could solve payment. If you can securely bind “this phone” to “this kiosk order session,” you can move sensitive input off the kiosk entirely.\n\nInstead of entering card data on a kiosk (high friction, public keyboard risk, and a compliance/attack surface headache), the kiosk would push the checkout step to the phone: the user would confirm the order and complete payment on their own device. Depending on the retailer/provider, this could be implemented as a tokenized flow or a redirect/hosted-payment style flow where card details never touched Storefront’s kiosk stack directly. That meant:\n\n- no need for specialized on-kiosk payment hardware across thousands of kiosks,\n- reduced exposure/compliance burden because payment details weren’t processed/stored on the kiosk,\n- better customer trust (pay on your phone instead of a public terminal), and\n- tighter transaction integrity in retail environments.\n\nOperationally, the system also reduced common retail loss modes. In deployments where kiosk orders were historically paid at the counter (and could be vulnerable to mismatch/shrinkage), the phone-based payment flow tightened the loop between “order created” and “order paid.” The measurable outcome was that after introducing payment through this mechanism, sales increased and shrinkage disappeared.\n\nCross-generation deployment\n\nA key design constraint was that the solution had to work across kiosk generations. The transfer + payment system was built as a modern service layer (Node.js/React for the user-facing pieces), designed to be adopted by both the legacy Windows kiosk fleet and the newer Android kiosks—so the same core session mechanics and backend services could be reused even as the kiosk hardware/software platform changed."
    },
    {
      "name": "What problem did The Kiosk File Transfer and Payment system solve?",
      "context": "The Kiosk File Transfer and Payment System solved two intertwined kiosk problems that became existential as consumer behavior shifted to smartphones: transfer friction and payment risk/cost.\n\nFirst, it solved the “getting photos onto the kiosk” problem. The old model assumed customers would bring a memory card, USB stick, or physically plug their phone into the kiosk. In practice, that was slow, confusing, and failure-prone: cables didn’t work, phones wouldn’t mount reliably, people didn’t carry the right adapters, and the whole experience felt increasingly out of date once photos lived primarily on phones. That friction wasn’t just annoying—it directly killed conversion at the exact moment customers were trying to start an order. The new flow removed physical connection entirely by letting a customer link their phone to the kiosk session (barcode/QR/short code) and upload photos wirelessly into a temporary session the kiosk could immediately use. The measurable impact was a major adoption lift: kiosk usage increased by roughly 50% once customers no longer had to plug their phones in.\n\nSecond, it solved the “payment on a public kiosk” problem. Taking credit cards directly on kiosks is expensive and risky: you either add specialized payment hardware (costly to install and maintain at fleet scale) or you force customers to type card details into a public terminal (high friction, poor trust, and bigger security/compliance exposure). By extending the same secure phone↔kiosk session handoff into checkout, payment could happen on the customer’s phone via secure tokenized and/or hosted/redirect flows—keeping sensitive card entry off the kiosk. That eliminated the need for on-device card hardware across thousands of kiosks and reduced the overall security/compliance burden of the kiosk environment.\n\nFinally, it solved a retail operations problem that mattered to partners: shrinkage and transaction mismatch. In some deployments, kiosk orders were historically paid at the counter, which can create opportunities for loss if the linkage between “order created” and “order paid” isn’t airtight. Moving payment into the same session flow tightened that linkage. After phone-based payment was introduced, sales increased and shrinkage disappeared—an outcome retailers care about as much as (or more than) feature upgrades.\n\nBecause the system was built as a modern service layer and designed to be kiosk-generation agnostic, it was adopted across both the legacy Windows kiosk fleet and the newer Android kiosks, turning what could have been a one-off feature into a durable platform capability."
    },
    {
      "name": "How does the file transfer work?",
      "context": "The kiosk file transfer flow replaced the old “bring media / plug your phone in” model with a phone-to-kiosk session handoff that worked reliably across a large retail fleet and across kiosk generations.\n\nAt a high level, the kiosk starts a short-lived transfer session and displays a QR code, and/or a short code. The customer uses their phone to scan or enter that identifier, which securely binds the phone to that specific kiosk session without requiring the kiosk to directly mount the phone’s storage. Once the session is established, the phone uploads selected photos over the network into a transient staging area keyed to the session. The kiosk then pulls those uploaded assets down (or is notified that they’re available) and presents them in the kiosk UI as if they had been imported locally—ready for browsing, editing, and product creation.\n\nThe implementation was intentionally “modern web” so it could evolve quickly and be reused across environments: a Node.js service handled session orchestration and APIs, while a React UI handled the phone-side experience (the step-by-step flow to connect, select images, upload, and confirm). The session model was designed to be compatible with both legacy Windows kiosks and the newer Android kiosks, so the transfer infrastructure could stay consistent even as kiosk hardware and kiosk application stacks changed.\n\nOperationally, the system was built around retail realities: sessions are time-bound and disposable, uploads are tied to explicit kiosk sessions to avoid cross-user mixups, and the backend is instrumented so support teams can diagnose failures (bad network, stalled uploads, kiosk connectivity issues) without guessing. The real proof it worked wasn’t architectural elegance—it was adoption: once customers no longer had to physically connect phones or bring USB media, kiosk usage increased by roughly 50%, because the first step of the funnel stopped being a frustration point."
    },
    {
      "name": "What about the payment system?",
      "context": "The payment system extended the same phone↔kiosk session handoff used for file transfer into checkout, with the goal of removing sensitive payment entry from a public kiosk and avoiding the cost/maintenance of specialized payment hardware at fleet scale.\n\nOnce a customer had built an order at the kiosk, the kiosk would present a “continue on your phone” payment step tied to the active session (again via a QR/barcode or short code). On the phone, the customer confirmed the order details and completed payment in a secure flow. Depending on the retailer/payment provider, this was implemented using tokenized and/or hosted redirect-style checkout so that card details did not need to pass through—or be stored on—the kiosk environment. That lowered security risk and reduced compliance scope compared to direct kiosk card entry, while also improving customer trust (people are naturally more comfortable paying on their own device than typing card data into a public terminal).\n\nFrom a business and operations perspective, this produced multiple concrete benefits:\n\n- Hardware cost avoidance: retailers could avoid installing and maintaining on-kiosk card readers and associated hardware across thousands of kiosks.\n- Lower support burden: fewer physical devices to fail, fewer in-store interventions, and fewer “payment peripheral” issues that require field service.\n- Better conversion: the phone-based flow reduced friction compared to kiosk card entry and improved the perceived safety of the transaction.\n- Stronger transaction integrity: in environments where kiosk orders were historically paid at the counter (which can create mismatches and shrinkage), binding payment to the same session tightened the linkage between “order created” and “order paid.”\n\nThe outcome matched the intent: after introducing payment through this approach, sales increased and shrinkage disappeared—an unusually strong result because it improves both revenue and loss prevention at the same time."
    },
    {
      "name": "What does the Remote Management Platform do?",
      "context": "The Storefront Remote Management Platform is the operational control plane for a large fleet of retail devices and connected services. It started as basic kiosk monitoring, but evolved into a system that let a small engineering/ops team keep thousands of kiosks—and the surrounding ecosystem of lab software and printers—running reliably across many retailers and countries.\n\nAt its core, the platform provided centralized visibility into device health and real-world retail failure modes. It didn’t just answer “is the kiosk alive?”—it tracked actionable states that affected revenue: kiosks down, stuck flows, out-of-paper/consumables, printer or lab connectivity issues, and other conditions that store staff could resolve quickly if they knew about them. That visibility mattered because in-store devices fail in messy ways, and without centralized telemetry you end up learning about outages from angry customers or store managers.\n\nBeyond monitoring, the platform enabled remote access and operational intervention. Support staff could retrieve detailed kiosk logs, pull diagnostics, and remotely inspect what was happening on devices without immediately resorting to expensive in-store visits. This was especially important early in large rollouts (e.g., Rite Aid), when the economics were brutal: the vendor doing in-store installs and service could make more money than the software vendor because every update or fix required a truck roll. Remote management shifted that equation—software updates, configuration changes, and many classes of fixes could be handled centrally instead of spending six figures on recurring field service.\n\nThe system also handled scheduling and controlled rollout behaviors. Retail fleets need “do it at 2am local time,” staged deployments, and guardrails so that a bad update doesn’t take out an entire chain at once. Remote management provided the machinery to coordinate those rollouts, apply configuration per retailer/location/device type, and verify that devices successfully picked up changes.\n\nFinally, it served as an operational feedback loop for product improvement. By instrumenting key points in the kiosk and web flows, the platform surfaced where customers abandoned or got stuck, which steps were slow or error-prone, and what issues were recurring in the field. That data helped prioritize high-leverage fixes and UX improvements based on actual behavior rather than guesses.\n\nIn short: the Remote Management Platform turned a sprawling set of kiosks, lab integrations, and printing dependencies into something that could be operated like a real product—observable, controllable, supportable, and updatable at scale."
    },
    {
      "name": "How does it handle 30,000+ devices?",
      "context": "Handling 30,000+ field-deployed devices is less about “big server” and more about designing the platform around fleet realities: noisy networks, intermittent connectivity, huge differences in device health, and the need for predictable load on the backend. The Remote Management Platform scaled by treating the device fleet as a distributed system with strict assumptions about batching, backoff, idempotency, and operational safety.\n\nThe first scaling decision was the device communication model. Devices were designed to “phone home” on a controlled cadence with lightweight health/telemetry payloads rather than holding long-lived connections that would be brittle in retail networks. Heartbeats, status summaries, and queued event reports were kept compact, and devices were encouraged to jitter and back off to avoid synchronized thundering-herd patterns (e.g., every kiosk in a chain rebooting after a power event and all checking in at once). On the server side, ingestion endpoints were designed to be stateless and horizontally scalable so throughput could grow by adding capacity rather than rewriting logic.\n\nSecond, the platform separated concerns between telemetry ingestion, operational workflows, and heavy support actions. “Normal” traffic—heartbeats, key metrics, error summaries—was optimized to be cheap and fast, supporting sustained throughput on the order of ~12,000 requests/minute. More expensive operations (log downloads, remote access sessions, bulk config changes) were treated as controlled workflows: queued, rate-limited, auditable, and executed with guardrails so support work wouldn’t starve the core monitoring pipeline.\n\nThird, scheduling and rollout were treated as first-class. At fleet scale you can’t just push updates; you need staged deployment, per-retailer/device-group targeting, and time-window controls (often local-time constraints) so updates don’t disrupt stores during peak hours. The platform supported scheduled actions and progressive rollout patterns so a bad change could be stopped early and so devices didn’t all fetch large updates simultaneously.\n\nFourth, data modeling and storage were designed around “query what matters quickly.” A fleet operator needs fast answers to questions like: which kiosks are down in the last 10 minutes, which stores are out of paper, which devices are stuck at a specific screen, and what error signatures are spiking today. That requires efficient indexing of current device state, plus retention of time-series/event history for trend analysis and debugging. The platform stored both “current state” (what is true now) and “event history” (what happened over time) so dashboards and alerts could be responsive without expensive recomputation.\n\nFinally, observability and failure isolation were critical. At 30,000 devices, something is always broken somewhere. The system had to tolerate partial failures: individual device misbehavior, partner network issues, bad configurations, and occasional backend hiccups. That meant strong defaults (timeouts, retries with backoff, idempotent operations) and good instrumentation so operators could see whether a spike was caused by a retailer network outage, a software regression, or a wave of devices hitting a known failure mode."
    },
    {
      "name": "How was scalability achieved?",
      "context": "Scalability came from designing the Remote Management Platform like a fleet control plane, not a “web app that happens to have devices.” The guiding principle was: make the steady-state device traffic cheap, keep the backend horizontally scalable, and treat expensive actions (updates, remote access, log pulls) as controlled workflows so they can’t overwhelm the system.\n\nOn the backend, core ingestion endpoints were built to be stateless and horizontally scalable. Devices sent periodic heartbeats and compact telemetry snapshots over short-lived connections, which mapped cleanly onto load-balanced services. That meant growth was mostly a capacity problem (scale out) rather than a redesign problem.\n\nOn the device side, check-ins were deliberately shaped to avoid a thundering herd. Devices were designed to phone home on a controlled cadence with jitter, retries with backoff, and sane timeouts. When a retailer had a power event or a chain-wide reboot, those patterns prevented “everything reconnects at once” from becoming “the backend falls over.” Device messages were also kept small and structured so that the common case (health, status, error summary) remained fast to ingest and cheap to store.\n\nThe platform also separated telemetry from heavy operational actions. The normal telemetry pipeline handled the high-throughput baseline. Log downloads, remote access sessions, configuration pushes, and software updates were treated as batch/queued work with throttling and rate limits. That prevented support operations from starving the monitoring pipeline and let the team run bulk actions safely across many stores."
    },
    {
      "name": "What monitoring capabilities does it have?",
      "context": "The Remote Management Platform’s monitoring was built around the realities of retail fleets: you don’t just need to know whether a kiosk is “up,” you need to know whether it’s able to sell, print, and recover without a technician standing beside it. The platform provided a centralized, near-real-time view of device health across kiosks, lab software, and printers, plus the tooling to turn those signals into action.\n\nAt the kiosk/device layer, monitoring covered both basic uptime and practical operational states. It tracked whether devices were reachable and healthy, but also surfaced the failure modes that actually stop revenue: stuck or looping application states, missing peripherals, printer connectivity problems, consumables issues (out of paper/media), and other conditions that store staff could fix quickly if they were informed. In other words, it focused on “is it selling?” not just “is it pinging?”\n\nThe platform also collected structured application telemetry and error reporting. Kiosks and related services emitted error summaries and key event signals that made it possible to spot regressions and recurring issues across the fleet. Instead of relying on anecdotal reports, the team could see error-rate spikes, correlate them to a recent rollout, and isolate whether the blast radius was one retailer, one region, one device model, or one specific workflow.\n\nA key capability was remote diagnostics: centrally pulling logs and device reports when something went wrong. That mattered because many issues were impossible to reproduce from a developer laptop—retail networking, local device state, bad media/cards, edge-case photos, and kiosk-specific hardware behaviors. Being able to retrieve “what the kiosk saw” (logs, state, error traces) dramatically reduced time-to-triage.\n\nMonitoring wasn’t only about crashes; it was also about customer behavior and funnel friction. The platform tracked key workflow milestones and where customers abandoned or got stuck (which pages/steps caused drop-off). That let the team prioritize fixes that improved conversion and reduced support load—using data rather than intuition.\n\nNet: centralized health + revenue-impact states, structured error/telemetry reporting, remote log/diagnostic retrieval, funnel/abandonment signals, and the operational hooks (alerts + scheduled actions) needed to turn monitoring into faster recovery and higher uptime as well as the ability login to devices remotely to investigate issues and distribute system and software updates."
    },
    {
      "name": "How did the distributed SaaS platform help partners?",
      "context": "The distributed SaaS platform helped partners add customizable photo and print-on-demand products without having to build (or maintain) the hard parts themselves—uploads, previews/editing, product configuration rules, order lifecycle, and fulfillment handoff. Instead of bespoke one-off builds per retailer, Kris helped deliver shared services and integration surfaces (APIs and embeddable experiences) that partners could adopt incrementally, which improved time-to-market and reduced long-term maintenance.\n\nA core focus was enabling photo-finishing products inside Shopify (with a path to other commerce platforms). The platform handled key integration needs—catalog/variant mapping, order ingestion and status, and fulfillment/lab handoff—while keeping the operational complexity on Storefront’s side. It also enabled “sell where the customer already is”: partners could embed Storefront’s personalization experience into their own sites (e.g., via an iframe-style integration) so customers could customize products without being bounced to a separate flow, improving conversion.\n\nBecause it was service-based, the platform also made modernization safer: legacy capabilities could be wrapped behind stable interfaces and gradually replaced over time, giving partners continuity while Storefront improved scalability, observability, and operability underneath."
    },
    {
      "name": "What microservices architecture was used?",
      "context": "The SaaS platform used a pragmatic microservices architecture centered on ~10 C# services connected through a Solace service bus, with the existing PHP monolith also participating on Solace via a custom PHP Solace library (so the monolith could run as a message loop and communicate asynchronously like the newer services). The intent was a “keep revenue running while changing engines” approach: add services around the monolith, move new development into those services, and gradually reduce direct coupling over time.\n\nThe services were split into two broad tiers:\n- Edge services: the front-door layer that talked to the web/frontend and acted like the controller layer (thin orchestration, request shaping, and composing responses).\n- Core services: domain-oriented services that implemented the business workflows and either (a) called into the PHP monolith via Solace or (b) increasingly took on responsibility by integrating directly with the underlying databases as ownership shifted.\n\nKey domain services included a Shop service that handled all Shopify communication (and was intended to be the integration point for future commerce engines like Wix/Woo/Magento/Stripe and other partners), a Payment service for payment processing flows, a File Write core service responsible for centralized file persistence, and an Imaging service for photo/imaging operations. This Solace-first architecture let Storefront add and evolve partner integrations and SaaS capabilities independently of the monolith, while still safely leveraging the proven legacy system until each capability could be carved out and owned by services."
    },
    {
      "name": "How do partners integrate?",
      "context": "Partners integrate via embeddable components and API integrations: a lightweight iframe-based personalizer for embedding product customization into partner sites, plus server-to-server APIs for order ingestion and fulfillment. The platform also supported partner-specific plugins and adapters so integrations could be tailored to each retailer’s fulfillment and inventory workflows."
    },
    {
      "name": "What did Kris study at Langara College?",
      "context": "Kris completed the Advanced Computer Studies and Technology Program (ACST) at Langara College in Vancouver, BC from 1995-1998. This technical program prepared him for his software development career."
    },
    {
      "name": "What was the ACST program like?",
      "context": "The Advanced Computer Studies and Technology (ACST) Program at Langara College was a comprehensive technical program covering computer science and software development fundamentals. Kris completed it from 1996-1998."
    },
    {
      "name": "How did this prepare you for your career?",
      "context": "The ACST program at Langara provided strong technical foundations in computer science and software development. Combined with practical internship experience at TRIUMF and Canfor during the same period, it launched Kris's 25+ year software development career.  While always planning to back to finish his BS in Computer Science, Kris was eager to start working in the industry and gain real-world experience (and having spent 7 of the previous 9 years in school, a little finiancial independence) and by the time the DotCom boom was in full swing it seemed foolish to leave to return to school."
    },
    {
      "name": "What skills did this provide?",
      "context": "The program emphasized practical skills: systems programming, debugging, documentation, and real-world deployment practices. It taught both technical fundamentals and the discipline required to ship reliable software—skills that shaped Kris’s approach to engineering and mentoring."
    },
    {
      "name": "What did Kris study at University of Western Ontario?",
      "context": "Kris graduated with an Honours BA in English Literature from the University of Western Ontario in 1993. This background has contributed to his strong communication and documentation skills throughout his technical career."
    },
    {
      "name": "How does English Literature help in tech?",
      "context": "Kris's English Literature degree contributes to his strong written communication, documentation skills, and ability to explain complex technical concepts clearly. He authored technical manuals at Langara College and continues to value clear communication in his leadership roles."
    },
    {
      "name": "Tell me about yourself/your career journey.",
      "context": "Situation: Kris has spent 25+ years building and modernizing revenue-critical software platforms, largely at Storefront/Macdonald Harris, where a small team delivered outsized impact across web, mobile, and large retail kiosk fleets.\nTask: Over time his role expanded from senior individual contributor to technical leadership—owning architecture, delivery, and production reliability for systems that had to keep running while evolving.\nAction: He helped evolve an early consulting engagement into a long-lived white-label commerce platform, then into high-volume photo commerce. He led and modernized key product lines: web ordering, Windows and Android kiosk platforms, a remote management/control plane for tens of thousands of devices, and newer distributed SaaS integrations (e.g., Shopify) while maintaining operational stability.\nResult: Kris has repeatedly delivered systems that stayed reliable under real-world constraints (retail hardware, multi-country deployments, legacy migrations) and produced measurable business outcomes—millions of prints/year, major retailers, and large-scale device operations—while also mentoring teams and improving delivery practices (CI/CD, testing, observability, release cadence)."
    },
    {
      "name": "What do you consider your greatest professional accomplishment?",
      "context": "Situation: Early in the Windows Photo Kiosk program, Storefront entered its kiosk in the PMA (Photographic Marketing Association) / DIMA kiosk competition in Las Vegas. The first year the kiosk performed poorly—crashing frequently during the event—and ended up in last place, viewed as one of the weakest entries.\n\nTask: Kris and the team needed to turn a fragile, crash-prone kiosk into a retail-grade product: stable under weird real-world inputs, resilient in front of customers and judges, and reliable enough to be trusted in stores.\n\nAction: Instead of cramming in more features for the next show, Kris helped drive a deliberate quality push focused on rock-solid reliability. In the months leading up to the following PMA, the team prioritized stability work: adding defensive error handling throughout the codebase, tightening edge-case handling, and stress-testing aggressively with the kinds of inputs that break kiosks in the wild—odd SD/memory cards, unexpected file formats, and every device/connection scenario they could throw at it (including phones and removable media). The goal was simple: make it extremely difficult to crash, and make failures graceful when they did occur.\n\nResult: One year later, the kiosk went from last-place instability to winning three of the four major kiosk awards at the show. It continued that winning streak for the next several years, until the competition was discontinued. For Kris, the accomplishment isn’t the trophy—it’s the transformation: proving that a small team could take a shaky early product and, through disciplined engineering and a reliability-first mindset, turn it into an award-winning, retail-ready system."
    },
    {
      "name": "What are your two greatest strengths, and what is one area you are actively working to improve?",
      "context": "Strength #1 (breadth with real depth): Kris can design architecture, implement the hard parts end-to-end, and keep systems stable in production across web, services, and large device fleets. He’s comfortable moving between frontend performance, backend reliability, and production debugging/observability without losing rigor.\n\nStrength #2 (pragmatic leadership + delivery): Kris prioritizes high-value work, keeps teams aligned with stakeholders, and builds repeatable delivery habits—small diffs, strong code review culture, tests, CI/CD, and good operational hygiene—that reduce heroics. He also genuinely enjoys mentoring and helping engineers grow, especially early-career developers, by sharing practical engineering judgment rather than just giving answers.\n\nImprovement area (transparent and practical): Kris wants deeper hands-on experience building and operating greenfield workloads in the major public clouds (AWS/GCP/Azure). He has worked within systems that ran in all three and understands the concepts, but his career at Storefront was shaped by an intentional “run it ourselves” approach—operating company-managed infrastructure (including Kubernetes) rather than pushing most workloads into managed cloud services. As a result, his gap isn’t understanding distributed systems or operations—it’s fewer reps with cloud-native managed primitives and day-one cloud setup. He’s actively addressing that by studying and building small, real deployments in cloud environments, and by applying the same operability mindset he used on-prem (CI/CD, observability, reliability) to cloud patterns so the learning translates into production-quality practice."
    },
    {
      "name": "Why are you looking to leave your current role/why did you leave your last role?",
      "context": "Situation: Storefront’s business was hit by a convergence of market shocks that reduced demand and revenue in ways the engineering team couldn’t “build around.” COVID disrupted retail and photo/kiosk usage patterns, and tariffs increased the cost basis for many print-on-demand products—pushing prices beyond what many customers were willing to pay.  The company needed to stay financially viable while its core markets were shrinking and its unit economics were getting worse.In the final phase at Storefront, the company was working to pivot into print-on-demand on Shopify—building a SaaS-style product that could compete in a crowded market alongside established players like Gelato, Printful, and Printify.\n\nTask: Kris’s mandate was to help deliver the product and get the platform to a production-ready state so the business could pursue that new growth channel.\n\nAction: The team successfully delivered the Shopify print-on-demand product and the underlying platform capabilities needed to support it. However, once the product existed, the company faced the larger go-to-market reality: breaking into that space would require a multi-million-dollar marketing and sales push to reach “pet competitor” scale and reliably acquire merchants at volume—investment the company wasn’t in a position to make.\n\nResult: Without the financing required to compete effectively in that market, leadership chose to dramatically reduce headcount—laying off most of the staff and keeping only a small group in “hold-on” roles to support the remaining business. Kris was laid off as part of that reduction. He’s now looking for a role where he can apply the same hands-on technical leadership, delivery discipline, and production ownership in an environment with a clearer path to market traction and sustainable growth."
    },
    {
      "name": "What is the most important thing you’re looking for in your next role/company?",
      "context": "Situation: After many years of building and operating revenue-critical systems, Kris knows he does his best work when the problems are real, the impact is measurable, and the team takes production ownership seriously.\n\nTask: Find a role that balances meaningful technical challenge with the chance to keep learning, stay hands-on, and help others grow.\n\nAction: Kris looks for a company where the work is genuinely interesting—either new problem domains he hasn’t lived in yet, or familiar domains with enough complexity to keep learning (scale, reliability, distributed systems, tough UX, or high-stakes integrations). He strongly values teams that ship with solid engineering fundamentals (thoughtful code review, testing, observability, incident learning) and that use modern tools—including AI-assisted development—with discipline rather than as a shortcut. Just as important, he’s drawn to environments where mentoring is part of the culture: he enjoys helping junior engineers break into the field and level up, and he likes sharing the “why” behind good engineering so people feel the craft—not just the grind.\n\nResult: The ideal next role is a place where Kris can stay close to architecture and code, keep expanding his skills, and contribute to a healthy culture—one with a mission he respects, teammates who care about quality, and leadership that values sustainable delivery over hype or constant reinvention."
    },
    {
      "name": "Describe your mentorship style. How have you helped a junior or senior engineer reach the next level?",
      "context": "Situation: Storefront teams included people with very different backgrounds—bootcamp grads with prior careers, strong seniors, and highly academic hires new to shipping business software.\nTask: Raise team capability without slowing delivery or lowering quality.\nAction: Kris mentors through real work: pairing on tough bugs, using reviews as teaching moments (asking questions, explaining tradeoffs), and giving ownership in safe increments (well-scoped components, clear success criteria). He sets expectations around production-grade habits—tests, logging/telemetry, small diffs, and thinking about failure modes. He also runs lightweight knowledge-sharing (lunch-and-learns, internal docs) and helps engineers build judgment, not just output.\nResult: Juniors ramp faster and become independently productive; seniors sharpen architecture and operational thinking; and the team develops a culture where quality and learning scale together."
    },
    {
      "name": "How do you handle building and maintaining team culture in a remote or hybrid environment?",
      "context": "Situation: The team shifted from in-office collaboration to mostly remote work post-COVID, with a smaller team and fewer “accidental hallway” touchpoints.\nTask: Maintain cohesion, alignment, and morale without adding heavy process.\nAction: Kris reinforces culture via predictable communication and shared ownership: clear priorities, tight feedback loops, and frequent but lightweight checkpoints. He uses code review norms that are constructive (not harsh), encourages pairing on tricky work, and creates spaces for learning (lunch-and-learns, internal demos). He also focuses on psychological safety—calling out good work, making it okay to ask questions, and keeping incident discussions blameless and improvement-oriented.\nResult: Teams stay connected and effective even when distributed, with fewer misunderstandings, less rework, and a stronger sense of shared responsibility for quality and production outcomes."
    },
    {
      "name": "How do you approach prioritizing technical debt versus new feature development when stakeholders are pushing for the latter?",
      "context": "Situation: Kris has spent much of his career in small teams under real deadlines, where the business sometimes needs a solution shipped now—even if it isn’t the most elegant version of the code.\n\nTask: Deliver features that move the business forward without letting “temporary” shortcuts harden into permanent fragility.\n\nAction: Kris is pragmatic about taking on debt when it’s the right tradeoff—he’s comfortable being a “duct-tape programmer” when needed to hit a date or unlock revenue—but he draws hard lines around safety and recoverability. If a solution is going to be imperfect, he insists on guardrails: (1) tests around the risky parts so the team can change it later with confidence, (2) feature flags / kill switches so the feature can be disabled quickly if it misbehaves in production, and (3) a delivery pipeline that makes recovery fast—tight CI, reliable builds, and the ability to ship fixes quickly without ceremony.\n\nHe also works to keep debt from becoming invisible. He frames it in stakeholder language (“this will slow future delivery,” “this increases outage risk,” “this will cost us support time”), and he schedules repayment the same way he schedules features: either by pairing cleanup with the next related change (“refactor the seam you’re touching anyway”) or by carving out targeted paydown when debt is actively hurting velocity or reliability. He avoids big rewrites, preferring incremental replacement that keeps revenue running while the system improves.\n\nResult: Stakeholders still get the features they need on time, but the team retains the ability to recover—debt stays intentional, bounded, and repayable. Kris believes in moving fast when required, but tries not to get into a situation where he is building a system that can’t be safely changed six months later."
    },
    {
      "name": "Describe a situation where you had to convince a team to adopt a technology or process they were resistant to.",
      "context": "Situation: When AI coding tools came into vogue, many developers at Storefront were skeptical. They used ChatGPT for quick questions and the occasional snippet, but earlier experiences with tools like Copilot had left a bad taste in their mouths, low-quality code, time lost cleaning up mistakes, and a general feeling that “this slows me down more than it helps.”\n\nTask: Kris wanted the team to benefit from the newer generation of AI-assisted development without creating a culture of blindly trusting generated code or producing unmaintainable messes.\n\nAction: Instead of mandating anything, Kris led by example and made the value visible. He took on a concrete, high-impact project and used AI heavily to prove what was possible with disciplined usage: he converted a major imaging subsystem from C# to JavaScript with roughly ~90% AI-assisted implementation. What would normally have taken weeks was completed in a couple of days, and it produced a product outcome everyone could feel: image rendering and editing moved closer to the browser, reducing the need for users to upload images to the server before they could work with them and improving perceived responsiveness.\n\nHe then turned that personal win into a team adoption path. Kris ran multiple lunch-and-learns where he demystified the tools and showed practical workflows: how to use AI to accelerate “busy work” like API documentation, how to scaffold demo-quality prototypes quickly with agents (e.g., Copilot), and even how to run local LLMs on a desktop using tools like AI Studio—while also being clear about the guardrails (small diffs, human review, tests, linting, and never trusting the model’s confidence).\n\nResult: Team sentiment shifted from “AI is frustrating and unreliable” to “AI is a lever if you use it correctly.” Adoption increased organically because developers could see the real throughput gains and quality improvements when AI was treated as an assistant, not an autopilot—saving time on repetitive work, accelerating refactors, and making it easier to explore solutions without sacrificing review rigor or production standards."
    },
    {
      "name": "Tell me about a high-pressure situation. What was your role in resolving it?",
      "context": "Situation: A Storefront e-commerce deployment was running in a configuration that didn’t require login and lacked the right abuse controls. Overnight it became a target for credit-card testing fraud: the system suddenly showed thousands of “orders” for the same product/image—clearly not real purchases.\n\nTask: Stop the abuse quickly, prevent unnecessary costs, protect the merchant, and harden the checkout flow so the site couldn’t be used as a card-testing tool again.\n\nAction: Kris treated it like an incident. He confirmed the pattern by reviewing order activity and operational signals, then identified the real financial exposure. While the fraudulent orders didn’t create fulfillment loss (nothing had been produced yet), every attempted checkout was triggering a paid postal/ZIP validation call—turning the attack into thousands of dollars of third-party validation fees.\n\nKris traced the root enabler to configuration: the merchant’s postal-code validation settings effectively had no rate limiting. Normal traffic was tens of checks per hour, but the site was allowing thousands per hour—exactly what automated card-testing needs. He immediately recommended enabling strict rate limits for those validation calls, and in parallel implemented product-side mitigations. The most direct was adding CAPTCHA in front of checkout/validation so automated flows would fail.\n\nHe also added pragmatic throttling and abuse checks in code: for example, limiting how many times a single IP address could order the same product within a defined window. Kris was explicit that IPs can be shared, but the thresholds were chosen to flag behavior that was wildly outside normal usage (e.g., 100+ orders/day for the same item from one IP), and to stop the obvious automation without impacting typical customers.\n\nFinally, Kris pushed for stronger perimeter protection so the platform wasn’t relying purely on application-layer defenses. He recommended that the SaaS/ops team run a proper Web Application Firewall in front of these deployments—using services like Cloudflare or AWS’s edge/WAF offerings—to provide additional bot mitigation, rate limiting, and rule-based protection upstream.\n\nResult: The abuse stopped, postal-code validation charges dropped back to normal, and the checkout flow was materially hardened. The response combined fast containment (rate limiting + CAPTCHA) with durable prevention (IP/product throttles, safer defaults, and WAF guidance), improving the overall security posture rather than just cleaning up the immediate incident."
    },
    {
      "name": "How do you explain a complex technical architecture to a non-technical stakeholder (like a CEO or a Customer)?",
      "context": "Situation: Kris frequently works with executives, partners, and business stakeholders who don’t need implementation details—they need clarity to make decisions about risk, cost, timelines, and customer impact.\n\nTask: Translate complex architecture into a decision-ready explanation that’s accurate, simple, and grounded in business outcomes.\n\nAction: Kris starts by asking what decision the person is trying to make, then explains the system in layers: the outcome first (what this enables), a simple mental model of the main moving parts, and the key tradeoffs expressed in plain language (speed vs risk, cost vs flexibility, “what breaks and how we recover”). He uses concrete user journeys to make it real, avoids jargon, and is explicit about what’s known vs uncertain. He also leans heavily on clear writing—his English degree and years of producing docs, incident notes, and partner-facing explanations have made him comfortable turning messy technical reality into something crisp and readable.\n\nResult: Stakeholders leave with a shared understanding of what’s being built, why it matters, what it will take, and where the real risks are—without needing to be technical to participate."
    },
    {
      "name": "Tell me about a time a project you were leading failed. What happened and what did you learn?",
      "context": "Situation: Early in Storefront’s Windows Photo Kiosk effort, the team brought the kiosk to the PMA trade show (and the demo/competition environment) where it would be judged in front of industry peers. In the month leading up to the show, the team was under pressure to match competitor feature lists and competition requirements.\n\nTask: Deliver a kiosk demo that was compelling enough to stand out—without embarrassing failures on the show floor.\n\nAction: The team took the wrong approach: they crammed in feature after feature right up to the last minute. Kris helped drive the push to increase capability, but the constant late changes created instability—insufficient time for regression testing, too many moving parts, and not enough hardening. At the show, the kiosk crashed repeatedly and performed poorly in the competition.\n\nResult: The kiosk effectively “failed” in the most public way: it was unstable during the event and finished last, viewed as one of the weakest entries.\n\nLearning: Kris took away a lesson he’s applied ever since: feature completeness is worthless if the product isn’t reliable. The next year, the team flipped the strategy—an enforced feature freeze roughly two months before the show, then all remaining time spent on fit-and-finish: bug fixing, error handling, edge-case testing, and polish. That change in process helped transform the kiosk into a stable, competitive product (and later an award winner), and it cemented Kris’s bias toward shipping a smaller, rock-solid MVP over a feature-heavy build that can’t be trusted."
    },
    {
      "name": "Tell me about a time you had to deliver bad news to a client or business stakeholder.",
      "context": "Situation: At the last minute a client wanted Storefront to integrate a payment provider using a direct-post model where card data would pass through Storefront’s systems as part of checkout.\n\nTask: Assess whether the integration was feasible to launch on the desired timeline without creating unacceptable security and compliance risk.\n\nAction: Kris reviewed what it would take to do this responsibly and concluded the scope wasn’t “just an API integration”—it would expand Storefront’s compliance obligations substantially (PCI DSS, security hardening, audit readiness, operational controls, and ongoing compliance work).  The server would have to moved to a PCI compliant cage in the data center, and a higher level audit of the code would be required. He delivered the bad news early and directly: the team could not safely support that provider and still hit the planned launch date. He reframed the decision around risk and outcomes (protect customers, avoid turning the platform into a card-data liability) and proposed an alternative path: use a redirect/hosted-payment flow where sensitive card data would not transit Storefront systems. Kris coordinated the pivot with the client and internal stakeholders, resetting expectations and sequencing the work to preserve the most important business goal: launching a secure checkout with minimal platform risk.\n\nResult: The launch was delayed, but the client shipped with a safer payment approach that avoided card data flowing through Storefront systems. The key outcome was maintaining stakeholder trust by being transparent about the tradeoffs, offering a credible alternative, and preventing a high-risk integration that could have created long-term compliance and security burden."
    },
    {
      "name": "What are some of Kris's hobbies or interests outside of work?",
      "context": "Outside of work, Kris stays active and curious. He enjoys travel and exploring new places, and keeps a steady rotation of outdoor activities including pickleball, biking, hiking, and skiing. He also reads widely, with a particular love of Victorian literature."
    },
    {
      "name": "What is Kris's communication style?",
      "context": "Kris communicates with a “clear, calm, and concrete” style that keeps both technical teams and business stakeholders aligned. He starts with a plain-language summary (what’s happening, why it matters, what the options are), then drills into details with examples, comparisons,  and explicit tradeoffs so decisions don’t get lost in ambiguity. His English Literature background shows up in how he writes: concise, readable, and structured—focused on helping people understand, not impressing them. In leadership settings, he translates stakeholder goals into actionable engineering plans, sets expectations early (scope, risks, sequencing), and keeps progress visible through regular updates and lightweight written artifacts (RFCs/notes/runbooks). In code reviews and mentoring, he’s constructive without being harsh—asking questions, pointing out risks, suggesting alternatives, and also calling out what’s strong so reviews feel like collaboration rather than judgment. During incidents, he prioritizes steady communication: status, impact, mitigation, and the follow-up learning that prevents repeats."
    },
    {
      "name": "Tell me about Kris's management experience",
      "context": "Kris’s management experience is grounded in leading small teams delivering software for enterprise retail partners. At Storefront, team size fluctuated with business cycles (roughly 15 developers at peak, ~10 on average, and ~6 in the final year), and Kris regularly coordinated across engineering, QA, PMs, and design to keep execution focused on the highest-value outcomes. As Director of Software Development, he owned the practical “glue” work: translating stakeholder goals into an executable roadmap, budgeting developer time, setting architecture standards and delivery practices, and staying accountable for uptime and on-call support when issues were code-related. His scope included full ownership of remote management, mobile apps, web front-end, internal store utilities, and partner-facing tooling (including a major personalization integration), plus shared responsibility for the Windows and Android kiosks and the Shopify/SaaS integration surface.\n\nKris is also a hands-on people manager who invests heavily in team growth. He was present in hiring, pairing, and establishing a healthy code-review culture, and he built mentorship around a wide range of backgrounds—from bootcamp grads with prior careers to PhD hires who were brilliant technically but new to business delivery. He emphasizes psychological safety and constructive feedback while keeping a high bar for production readiness (tests, observability, small diffs, reliable CI/CD). After COVID shifted the company from in-office to mostly remote, he worked intentionally to keep connections strong—using routines like lunch-and-learns, clear written communication, and consistent expectations—so the team could ship predictably without burnout or heroics."
    },
    {
      "name": "What is your approach to giving feedback?",
      "context": "Kris treats feedback as a coaching tool, not a verdict. He aims to make it specific, actionable, and tied to outcomes (correctness, maintainability, operability, customer impact), while keeping the tone calm and respectful so people don’t dread reviews. In code reviews especially, he considers it essential to call out what’s strong—not as fluff, but because it reinforces good judgment, helps the author know what to repeat, and makes the “needs work” parts easier to hear.\n\nInstead of dropping a final answer or prescribing a solution, Kris usually leads with questions that help the developer think through tradeoffs themselves: “What happens on failure?”, “How would we test this edge case?”, “Would your average user expect this to happen?”, “Is there a simpler design that preserves the intent?”, “What’s the performance/caching impact?” That approach teaches decision-making, not just compliance.\n\nWhen the feedback is negative or the change needs rework, he frames it in a way that preserves momentum: start by grounding the review in what’s working and what the change is accomplishing, then clearly explain the risks or gaps (with concrete examples), and finish with a path forward—options, next steps, or a small set of high-leverage changes that will get it over the line. The goal is for the person to leave the review feeling supported and sharper, not deflated."
    },
    {
      "name": "What is your greatest asset?",
      "context": "Kris’s greatest asset is being a pragmatic, production-first problem solver who can span architecture, implementation, and operations—and keep systems (and teams) moving forward under real constraints. He’s known for debugging what’s actually going wrong, whether that’s a tricky production issue in code, an unexpected interaction between systems, or a human/organizational problem where misalignment is the real root cause. He pairs that with strong communication: he can explain complex technical realities clearly, align stakeholders, and turn ambiguity into an executable plan.\n\nUnderneath it all is a genuine love of the craft. Kris is consistently drawn to new methodologies and technologies—not for novelty, but for leverage—and he keeps learning so he can apply better tools and better practices as they emerge. The result is a rare mix: breadth with real depth, steady delivery, and the ability to make both the software and the people around it stronger over time."
    },
    {
      "name": "Give an example of a crisis you faced and how you dealt with it",
      "context": "Situation: A revenue-critical e-commerce site was suddenly hit by fraudulent checkout activity. Overnight, it generated an abnormal spike of repeated orders for the same product, and while the orders weren’t fulfilled (so there was no direct inventory loss), the traffic triggered expensive third-party verification calls—creating real, immediate cost exposure.\n\nTask: Stop the abuse fast, contain costs, protect legitimate customers, and put durable controls in place so the issue wouldn’t recur.\n\nAction: Kris treated it like an incident: he started with logs and telemetry to confirm the pattern, identify the affected flows, and determine the fastest safe mitigations. He coordinated rapid changes that reduced the site’s usefulness for automated abuse: tightening rate limits (including correcting overly-permissive partner settings), adding a CAPTCHA step before checkout, and implementing additional guardrails in code (for example, limiting repeated purchases of the same product from the same IP over a defined time window). In parallel, he pushed for stronger perimeter defenses—recommending the use of a proper WAF (e.g., Cloudflare-style protection) and aligning internal stakeholders on monitoring and alerting so unusual spikes would be caught earlier.\n\nResult: The attack was contained, ongoing third-party verification costs were stopped, and the platform emerged measurably more resilient. The follow-on outcome was a stronger security posture (rate limiting, bot resistance, anomaly detection mindset) and a clearer playbook for responding quickly without breaking legitimate customer checkout."
    },
    {
      "name": "How do you handle criticism?",
      "context": "Kris treats criticism as signal, not as a verdict anmd tries not to take things too personally. His first move is to make sure he understands what’s actually being said—he’ll ask clarifying questions, restate it in his own words, and separate objective issues (facts, outcomes, constraints) from subjective preference (style, taste, “how we usually do it”). If the feedback is valid he proposes a concrete adjustment, makes the change, and follows up to confirm it solved the underlying concern.\n\nIf the feedback feels off, he tries not get too defensive; he looks for the misunderstaning knowing that the commenter might have different goals, or unspoken constraints—and works to align on what “good” looks like. He’s comfortable saying “I might be wrong—help me understand,” but after hearing out the opinion he will be willing to say “I disagree, and here’s why,” while staying respectful and focused on outcomes. Over time he’s learned that the best way to handle criticism is to convert it into an challenge or see it as somethign that cane have a measurable improvement, then try to close the loop so trust increases rather than erodes (even though sometimes that is not always possible)."
    },
    {
      "name": "What are your core values as a software developer and manager?",
      "context": "Deliver the highest quality solution to the client.  This sometimes means preferring practicality over elegance or prioritizing more important features done correctly rather than completing all the features in a fragile manner.  To me it also means working in an agile way, creating an MVP and continually improving rather than trying to produce the perfect complete product whole cloth.  I prefer simple solutions over highly optimized and complex solutions until optimization is required, not only for the speed of delivery but for clarity and readability at a later date.  For this reason I believe that technology should be evaluated and used when it has proven itself over time, not just because it is the hottest new thing (those are great to keep an eye on for personal side projects until they prove themselves). As a manager I try to project these values as well as other important aspects of the craft: always ask questions – too many errors, delays, and failures stem from not only misunderstanding specifications but also from not enough questions in general before development begins - or not raising issues once development has begun and potential weaknesses in the design become apparent.  I believe in mentoring developers by guiding them to discover solutions themselves or by asking pointed questions rather than telling them the solution immediately."
    },
    {
      "name": "What was the last technical project that energized you?",
      "context": "I was in charge of adding mobile payment to our Android Photo Kiosk.  I had previously developed a photo uploader that worked by scanning a QR code on the kiosk, which directed you to a website that you accessed on your phone where you could upload photos and they would be transferred to the kiosk.  We needed a way to remove the cost of a credit card reader (which ended up costing more than the kiosk) but still be able to take payment on the kiosk.  We realized that we could reuse the same concept and some of the code for payment. When the user reached the payment phase, the kiosk would display a QR code. The kiosk would then communicate the amount owed, along with other transaction details, to the website.  When the user visited the website they would be shown their order, and then brought through a payment flow (depending upon the retailer where the kiosk was located a different payment gateway would have to be used, Authorize.Net, Stripe, Google Pay, PayPal), which when successful would send a message back to the kiosk over a websocket that order was paid for and to inform the user, and our order-fulfillment server that the order could be produced.  The tech stack for this was Node.js (Express) and React on the web server and Vue.js, TypeScript and Java on the Photo Kiosk - I was completely responsible for the web server and React webpage and helped a lot on the kiosk side getting the WebSockets to work and Java service to interop properly with Vue.js on the kiosk.  This project energized me because of how elegantly it solved a problem for us (payment hardware was expensive)  but it was an interesting interaction of multiple systems (kiosk, client mobile device, order fulfillment system, payment gateway) that had to work seamlessly.  It needed extensive e2e testing, hardened security, as well as utilizing a host of varied technologies: multiple REST APIs, WebSockets, database, a message bus, and OpenTelemetry to keep an eye on all stages of the payment process."
    },
    {
      "name": "If you were asked to quickly ship an MVP, how would you approach it?",
      "context": "The answer is of course, ”it depends”, which is a bit trite but pretty much always true.  But, for example, if I were to ship an MVP for a frontend or a frontend feature I would now be using generative AI (from month to month the best product for this changes, but over the past 3 months it has been Cursor or Claude Code or Antigravity)  to build what we used to do as a paper prototype (which then switched to something designed in Figma).  If there was already a general design or even initial mockups these would be used as the starting point.  I’ve found these throw-away prototypes great for working through a bunch of issues,  and since the code is throw-away you don’t really have to spend much time validating the code.  If it needed API endpoints, I would have AI generate a bunch of realistic mock results (another thing AIs are pretty good at) so that the UI actually works as expected.  Iterate for a while on the AI-generated mock.  Then when happy with the mock show it to colleagues (for feedback) and after working through the feedback, show it to the various stake-holders.  Once the stake-holders are happy with the mock, you can figure out what the most important features of the prototype are and start implementing them as the MVP.  In the past, as things changed in the real implementation, I tried to keep the prototype up-to-date but I have found that the models started to have problems as the mock became more complicated, and I found it difficult keeping the mock in sync with the real feature without a lot of intervention, but as the models get better this might change."
    },
    {
      "name": "What are some your favorite blog posts you have written?",
      "context": "I have written a number of blog posts over the years, but some of my favorites are: 1) the series I wrote on supervised learning: https://agingcoder.com/posts/experiments-in-supervised-learning/, 2) an article looking at whether or not an LLM can beat a traditional supervised model https://agingcoder.com/posts/can-a-tiny-llm-beat-a-supervised-model/, 3) A look into the failures of AI, called The Trough of Disillusionment https://agingcoder.com/posts/the-trough-of-disillusionment/, 4) Historically my most popular posts is from 10 yhears ago called the state of HTML moible frameworks in 2016 (https://agingcoder.com/posts/the-state-of-html-mobile-frameworks-in-2016/), which is still getting views today. 5) Actually my most popular post is my SLOC counter https://agingcoder.com/posts/sloc-counter/ which is ironic since https://utiliti.dev (project I worked on with Hussein) now does a much better job at counting SLOC than my little script ever did and right at the top of the post is a link to utiliti.dev."
    }
  ]
}